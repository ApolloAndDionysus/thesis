%
% 1933
%

@article{10.2307/2332286,
 author = {William R. Thompson},
 journal = {Biometrika},
 number = {3/4},
 pages = {285-294},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples},
 volume = {25},
 year = {1933}
}


%
% 1945
%

@Article{Wald45SPRT,
  Title                    = {{Sequential Tests of Statistical Hypotheses}},
  Author                   = {Wald, A.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1945},
  Pages                    = {117--186},
  Volume                   = {16(2)},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.01.25}
}


%
% 1984
%

@article{csiszar1984,
author = "Csiszar, Imre",
doi = "10.1214/aop/1176993227",
fjournal = "The Annals of Probability",
journal = "Ann. Probab.",
month = "08",
number = "3",
pages = "768--793",
publisher = "The Institute of Mathematical Statistics",
title = "Sanov Property, Generalized $I$-Projection and a Conditional Limit Theorem",
volume = "12",
year = "1984"
}


%
% 1985
%

@article{Lai19854,
title = "Asymptotically efficient adaptive allocation rules ",
journal = "Advances in Applied Mathematics ",
volume = "6",
number = "1",
pages = "4 - 22",
year = "1985",
note = "",
issn = "0196-8858",
doi = "http://dx.doi.org/10.1016/0196-8858(85)90002-8",
author = "T.L Lai and Herbert Robbins"
}

@book{WaldsLemma,
title  = {Sequential Analysis},
author = {David Siegmund},
year = {1985},
}



%
% 1990
%

@INPROCEEDINGS{Schapire90thestrength,
    author = {Robert E. Schapire},
    title = {The Strength of Weak Learnability},
    booktitle = {Machine Learning},
    year = {1990}
}


%
% 1991
%

@book{Cover:1991:EIT:129837,
 author = {Cover, Thomas M. and Thomas, Joy A.},
 title = {Elements of Information Theory},
 year = {1991},
 isbn = {0-471-06259-6},
 publisher = {Wiley-Interscience},
 address = {New York, NY, USA},
} 


%
% 1992
%

@Article{Weber92,
  Title                    = {{On the {G}ittins index for multiarmed bandits}},
  Author                   = {Weber, R.},
  Journal                  = {Annals of Applied Probabilities},
  Year                     = {1992},
  Pages                    = {1024--1033},
  Volume                   = {2(4)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}


%
% 1993
%

@book{Quinlan:1993:CPM:152181,
 author = {Quinlan, J. Ross},
 title = {C4.5: Programs for Machine Learning},
 year = {1993},
 isbn = {1-55860-238-0},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 


%
% 1995
%

@Article{Agrawal:95,
  Title                    = {{Sample mean based index policies with O(log n) regret for the multi-armed bandit problem}},
  Author                   = {Agrawal, R.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {1054--1078},
  Volume                   = {27},

  Publisher                = {JSTOR}
}

@article{Freund:1995:BWL:220262.220446,
 author = {Freund, Yoav},
 title = {Boosting a Weak Learning Algorithm by Majority},
 journal = {Inf. Comput.},
 issue_date = {Sept. 1995},
 volume = {121},
 number = {2},
 month = sep,
 year = {1995},
 issn = {0890-5401},
 pages = {256--285},
 numpages = {30},
 doi = {10.1006/inco.1995.1136},
 acmid = {220446},
 publisher = {Academic Press, Inc.},
 address = {Duluth, MN, USA},
}


%
% 1996
%

@article{Burnetas1996122,
title = "Optimal Adaptive Policies for Sequential Allocation Problems ",
journal = "Advances in Applied Mathematics ",
volume = "17",
number = "2",
pages = "122 - 142",
year = "1996",
note = "",
issn = "0196-8858",
doi = "http://dx.doi.org/10.1006/aama.1996.0007",
author = "Apostolos N. Burnetas and Michael N. Katehakis"
}

@inproceedings{Quinlan:1996:BBC:1892875.1892983,
 author = {Quinlan, J. R.},
 title = {Bagging, Boosting, and C4.S},
 booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 1},
 series = {AAAI'96},
 year = {1996},
 isbn = {0-262-51091-X},
 location = {Portland, Oregon},
 pages = {725--730},
 numpages = {6},
 acmid = {1892983},
 publisher = {AAAI Press},
}

@inproceedings{Freund:1996:ENB:3091696.3091715,
 author = {Freund, Yoav and Schapire, Robert E.},
 title = {Experiments with a New Boosting Algorithm},
 booktitle = {Proceedings of the Thirteenth International Conference on International Conference on Machine Learning},
 series = {ICML'96},
 year = {1996},
 isbn = {1-55860-419-7},
 location = {Bari, Italy},
 pages = {148--156},
 numpages = {9},
  acmid = {3091715},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}


%
% 1997
%

@article{berry1997,
author = "Berry, Donald A. and Chen, Robert W. and Zame, Alan and Heath, David C. and Shepp, Larry A.",
doi = "10.1214/aos/1069362389",
fjournal = "The Annals of Statistics",
journal = "Ann. Statist.",
month = "10",
number = "5",
pages = "2103--2116",
publisher = "The Institute of Mathematical Statistics",
title = "Bandit problems with infinitely many arms",
volume = "25",
year = "1997"
}


%
% 1998
%

@ARTICLE{Friedman98additivelogistic,
    author = {Jerome Friedman and Trevor Hastie and Robert Tibshirani},
    title = {Additive Logistic Regression: a Statistical View of Boosting},
    journal = {Annals of Statistics},
    year = {1998},
    volume = {28},
    pages = {2000}
}

@ARTICLE{726791, 
author={Y. Lecun and L. Bottou and Y. Bengio and P. Haffner}, 
journal={Proceedings of the IEEE}, 
title={Gradient-based learning applied to document recognition}, 
year={1998}, 
volume={86}, 
number={11}, 
pages={2278-2324},  
doi={10.1109/5.726791}, 
ISSN={0018-9219}, 
month={Nov},
}

@Book{Vapnik98,
  Title                    = {{Statistical Learning Theory}},
  Author                   = {V.~Vapnik},
  Publisher                = {Wiley},
  Year                     = {1998},

  Address                  = {New York}
}



%
% 1999
%

@incollection{Platt:1999:FTS:299094.299105,
 author = {Platt, John C.},
 chapter = {Fast Training of Support Vector Machines Using Sequential Minimal Optimization},
 title = {Advances in Kernel Methods},
 editor = {Sch\"{o}lkopf, Bernhard and Burges, Christopher J. C. and Smola, Alexander J.},
 year = {1999},
 isbn = {0-262-19416-3},
 pages = {185--208},
 numpages = {24},
 acmid = {299105},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}


%
% 2001
%

@inproceedings{Escudero:2001:ULW:2387364.2387381,
 author = {Escudero, G. and M\`{a}rquez, L. and Rigau, G.},
 title = {Using LazyBoosting for Word Sense Disambiguation},
 booktitle = {The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems},
 year = {2001},
 
}


%
% 2002
%

@inproceedings{FriedmanStochasticGB,
  title={Stochastic Gradient Boosting},
  author={J. H. Friedman},
  year={2002},
  booktitle = {In Computational Statistics \& Data Analysis, 2002.}
}

@ARTICLE{991427, 
author={Chih-Wei Hsu and Chih-Jen Lin}, 
journal={IEEE Transactions on Neural Networks}, 
title={A comparison of methods for multiclass support vector machines}, 
year={2002}, 
volume={13}, 
number={2}, 
pages={415-425}, 
doi={10.1109/72.991427}, 
ISSN={1045-9227}, 
month={Mar},}


%
% 2004
%

@ARTICLE{Mannor04thesample,
    author = {Shie Mannor and John N. Tsitsiklis and Kristin Bennett and Nicolò Cesa-bianchi},
    title = {The Sample Complexity of Exploration in the Multi-Armed Bandit Problem},
    journal = {Journal of Machine Learning Research},
    year = {2004},
    volume = {5},
    pages = {2004}
}

@article{Lewis:2004:RNB:1005332.1005345,
 author = {Lewis, David D. and Yang, Yiming and Rose, Tony G. and Li, Fan},
 title = {RCV1: A New Benchmark Collection for Text Categorization Research},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2004},
 volume = {5},
 month = dec,
 year = {2004},
 issn = {1532-4435},
 pages = {361--397},
 numpages = {37},
 acmid = {1005345},
 publisher = {JMLR.org},
}


%
% 2006
%

@article{Even-Dar:2006:AES:1248547.1248586,
 author = {Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
 title = {Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2006},
 volume = {7},
 month = dec,
 year = {2006},
 issn = {1532-4435},
 pages = {1079--1105},
 numpages = {27},
 acmid = {1248586},
 publisher = {JMLR.org},
}


%
% 2007
%

@conference {4270071,
	title = {Feature Mining for Image Classification},
	booktitle = { IEEE Conference on Computer Vision and Pattern Recognition (CVPR {\textquoteright}07)},
	year = {2007},
	month = {June},
	pages = {1-8},
	keywords = {computer vision, data mining, feature extraction, feature mining, image analysis, image classification, learning (artificial intelligence)computer vision, machine learning, pedestrian classification},
	doi = {10.1109/CVPR.2007.383046},
	author = {Dollar, P. and Zhuowen Tu and Tao, H. and Belongie, S.}
}


%
% 2008
%

@incollection{NIPS2007_3321,
title = {FilterBoost: Regression and Classification on Large Datasets},
author = {Bradley, Joseph K and Schapire, 
 E},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {J. C. Platt and D. Koller and Y. Singer and S. T. Roweis},
pages = {185--192},
year = {2008},
publisher = {Curran Associates, Inc.},
}

@inproceedings{implementing-decision-trees-and-forests-on-a-gpu,
author = {Sharp, Toby},
title = {Implementing Decision Trees and Forests on a GPU},
booktitle = {ECCV (4)},
year = {2008},
month = {January},
publisher = {Springer},
address = {},
pages = {595-608},
journal = {},
volume = {5305},
chapter = {},
isbn = {978-3-540-88692-1},
}

@article{articleWuEtAl,
author = {Wu, Jianxin and Charles Brubaker, S and D Mullin, Matthew and Rehg, James},
year = {2008},
month = {04},
pages = {369-82},
title = {Fast Asymmetric Learning for Cascade Face Detection},
volume = {30},
booktitle = {IEEE transactions on pattern analysis and machine intelligence}
}


%
% 2009
%

@incollection{NIPS2008_3452,
title = {Algorithms for Infinitely Many-Armed Bandits},
author = {Yizao Wang and Jean-yves Audibert and R\'{e}mi Munos},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
year = {2009},
}

@unknown{PaulBiswajitAthithanEtAl,
author = {Paul, Biswajit and Athithan, G and Murty, M},
year = {2009},
month = {03},
pages = {251 - 254},
title = {Speeding up AdaBoost Classifier with Random Projection},
booktitle = {Proceedings of the 7th International Conference on Advances in Pattern Recognition, ICAPR 2009}
}



%
% 2010
%

@inproceedings{busafekete:in2p3-00614564,
  TITLE = {{Fast boosting using adversarial bandits}},
  AUTHOR = {Busa-Fekete, R. and K{\'e}gl, B.},
  NOTE = {http://www.machinelearning.org},
  BOOKTITLE = {{Proceedings of the 27th International Conference on Machine Learning (ICML)}},
  YEAR = {2010},
  PDF = {http://hal.in2p3.fr/in2p3-00614564/file/Busa-Fekete.pdf},
  HAL_ID = {in2p3-00614564},
  HAL_VERSION = {v1},
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanS10,
  author    = {Shivaram Kalyanakrishnan and
               Peter Stone},
  title     = {Efficient Selection of Multiple Bandit Arms: Theory and Practice},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
               (ICML-10), June 21-24, 2010, Haifa, Israel},
  pages     = {511--518},
  year      = {2010},
  timestamp = {Fri, 12 Jun 2015 19:15:11 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/colt/AudibertBM10,
  author    = {Jean{-}Yves Audibert and
               S{\'{e}}bastien Bubeck and
               R{\'{e}}mi Munos},
  title     = {Best Arm Identification in Multi-Armed Bandits},
  booktitle = {{COLT} 2010 - The 23rd Conference on Learning Theory, Haifa, Israel,
               June 27-29, 2010},
  pages     = {41--53},
  year      = {2010},
  timestamp = {Tue, 19 Feb 2013 17:09:31 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Book{AllOfStats,
  Title                    = {{All of Statistics: A concise course in statistical inference}},
  Author                   = {Wasserman, L.},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}


%
% 2011
%

@article{DBLP:journals/corr/abs-1111-1797,
  author    = {Shipra Agrawal and
               Navin Goyal},
  title     = {Analysis of Thompson Sampling for the multi-armed bandit problem},
  journal   = {CoRR},
  volume    = {abs/1111.1797},
  year      = {2011},
  timestamp = {Mon, 05 Dec 2011 18:05:11 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{journals/jmlr/GarivierC11,
  added-at = {2013-11-25T00:00:00.000+0100},
  author = {Garivier, Aurélien and Cappé, Olivier},
  biburl = {http://www.bibsonomy.org/bibtex/2eaa70f360a064c34e95c79775fd5aaa8/dblp},
  booktitle = {COLT},
  crossref = {conf/colt/2011},
  editor = {Kakade, Sham M. and von Luxburg, Ulrike},
  ee = {http://www.jmlr.org/proceedings/papers/v19/garivier11a/garivier11a.pdf},
  interhash = {2f239ff7ecaa45d8963b3db2978c960e},
  intrahash = {eaa70f360a064c34e95c79775fd5aaa8},
  keywords = {dblp},
  pages = {359-376},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2015-06-19T12:47:52.000+0200},
  title = {The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp19.html#GarivierC11},
  volume = 19,
  year = 2011
}


%
% 2012
%

@article{DBLP:journals/corr/abs-1202-3639,
  author    = {Karthekeyan Chandrasekaran and
               Richard M. Karp},
  title     = {Finding the most biased coin with fewest flips},
  journal   = {CoRR},
  volume    = {abs/1202.3639},
  year      = {2012},
  timestamp = {Mon, 20 May 2013 16:58:44 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/abs-1209-1380,
  author    = {Matthew Malloy and
               Gongguo Tang and
               Robert D. Nowak},
  title     = {The Sample Complexity of Search over Multiple Populations},
  journal   = {CoRR},
  volume    = {abs/1209.1380},
  year      = {2012},
  timestamp = {Wed, 10 Oct 2012 21:28:55 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{NIPS2012_4640,
title = {Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence},
author = {Gabillon, Victor and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
year = {2012},
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanTAS12,
  author    = {Shivaram Kalyanakrishnan and
               Ambuj Tewari and
               Peter Auer and
               Peter Stone},
  title     = {{PAC} Subset Selection in Stochastic Multi-armed Bandits},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning,
              (ICML)},
  year      = {2012},
}



%
% 2013
%

@inproceedings{icml2013_appel13, 
    Author = {Ron Appel and Thomas Fuchs and Piotr Dollar and Pietro Perona}, 
    Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML)}, 
    Title = {Quickly Boosting Decision Trees -- Pruning Underachieving Features Early}, 
    Year = {2013}, 
}

@inproceedings{icml2013_karnin13, 
    Author = {Zohar Karnin and Tomer Koren and Oren Somekh}, 
    Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)}, 
    Title = {Almost Optimal Exploration in Multi-Armed Bandits}, 
    Year = {2013}, 
}

@incollection{NIPS2013_5109,
title = {Two-Target Algorithms  for Infinite-Armed   Bandits with Bernoulli Rewards},
author = {Bonald, Thomas and Prouti\`ere, Alexandre},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
year = {2013},
}

@inproceedings{DBLP:conf/colt/KaufmannK13,
  author    = {Emilie Kaufmann and
               Shivaram Kalyanakrishnan},
  title     = {Information Complexity in Bandit Subset Selection},
  booktitle = {{COLT} 2013 - The 26th Annual Conference on Learning Theory, June
               12-14, 2013, Princeton University, NJ, {USA}},
  pages     = {228--251},
  year      = {2013},
  timestamp = {Thu, 11 Sep 2014 07:28:56 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{2013arXiv1302.1611B,
   author = {{Bubeck}, S. and {Perchet}, V. and {Rigollet}, P.},
    title = "{Bounded regret in stochastic multi-armed bandits}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1302.1611},
 primaryClass = "math.ST",
 keywords = {Mathematics - Statistics Theory, Computer Science - Learning, Statistics - Machine Learning, 62L05},
     year = 2013,
    month = feb,
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


%
% 2014
%

@article{Dubout:2014:ASL:2627435.2638580,
 author = {Dubout, Charles and Fleuret, Fran\c{c}ois},
 title = {Adaptive Sampling for Large Scale Boosting},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 issn = {1532-4435},
 pages = {1431--1453},
 numpages = {23},
 acmid = {2638580},
 publisher = {JMLR.org},
 keywords = {boosting, feature selection, large scale learning},
}

@article{10.1109/CISS.2014.6814096,
  author    = {Jamieson, K. and 
              Nowak, R},
  title     = {Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting},
  journal   = {Information Sciences and Systems (CISS)},
  year      = {2014},
  pages     = {1-6},
  publisher = {IEEE}
  
}

@article{10.1007/978-3-662-44848-9_20,
  author    = {Yahel David and Nahum Shimkin},
  title     = {Infinitely Many-Armed Bandits with Unknown Value Distribution},
  journal   = {European Conference, ECML PKDD},
  year      = {2014},
  pages     = {307-322},
  publisher = {Springer Berlin Heidelberg}
  
}

@ARTICLE{2014arXiv1407.4443K,
   author = {{Kaufmann}, E. and {Capp{\'e}}, O. and {Garivier}, A.},
    title = "{On the Complexity of Best Arm Identification in Multi-Armed Bandit Models}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1407.4443},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2014,
    month = jul,
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{DBLP:conf/nips/ChenLKLC14,
  author    = {Shouyuan Chen and
               Tian Lin and
               Irwin King and
               Michael R. Lyu and
               Wei Chen},
  title     = {Combinatorial Pure Exploration of Multi-Armed Bandits},
  booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
               on Neural Information Processing Systems 2014, December 8-13 2014,
               Montreal, Quebec, Canada},
  pages     = {379--387},
  year      = {2014},
  timestamp = {Wed, 10 Dec 2014 21:34:12 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


%
% 2015
%

@article{arXiv:1502.00133,
  author    = {Kevin Jamieson, Sumeet Katariya, Atul Deshpande and Robert Nowak},
  title     = {Sparse Dueling Bandits},
  journal   = {AISTATS},
  year      = {2015},
  publisher = {MathPubs}
  
}

@misc{kauf_email,
  author = "Emilie Kaufmann",
  year = 2015,
  month = dec,
  howpublished = "Personal communication"
}

@article{Lampret:2015:ADI:2828645.2828929,
 author = {Lampret, Vito},
 title = {Accurate Double Inequalities for Generalized Harmonic Numbers},
 journal = {Appl. Math. Comput.},
 issue_date = {August 2015},
 volume = {265},
 number = {C},
 month = aug,
 year = {2015},
 issn = {0096-3003},
 pages = {557--567},
 numpages = {11},
 url = {http://dx.doi.org/10.1016/j.amc.2015.04.128},
 doi = {10.1016/j.amc.2015.04.128},
 acmid = {2828929},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {11Y60, 33E20, 33F05, 40A25, 41A60, 65B10, 65B15, Approximation, Estimate, Euler-Maclaurin summation, Generalized harmonic number, Zeta-generalized-Euler-constant function, p-series},
}

@article{DBLP:journals/corr/CarpentierV15,
  author    = {Alexandra Carpentier and
               Michal Valko},
  title     = {Simple regret for infinitely many armed bandits},
  journal   = {CoRR},
  volume    = {abs/1505.04627},
  year      = {2015},
  timestamp = {Mon, 01 Jun 2015 14:13:54 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{NIPS2015_6027,
title = {On Top-k Selection in Multi-Armed Bandits and Hidden Bipartite Graphs},
author = {Cao, Wei and Li, Jian and Tao, Yufei and Li, Zhize},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N.D. Lawrence and D.D. Lee and M. Sugiyama and R. Garnett and R. Garnett},
pages = {1036--1044},
year = {2015},
publisher = {Curran Associates, Inc.},
}


%
% 2016
%

@inproceedings{Jamieson:2016wd,
author = {Jamieson, Kevin and Haas, Daniel and Ben Recht},
title = {{The Power of Adaptivity in Identifying Statistical Alternatives}},
booktitle= {Advances on Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{Kaufmann:2016:CBI:2946645.2946646,
 author = {Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
 title = {On the Complexity of Best-arm Identification in Multi-armed Bandit Models},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1--42},
 numpages = {42},
 url = {http://dl.acm.org/citation.cfm?id=2946645.2946646},
 acmid = {2946646},
 publisher = {JMLR.org},
 keywords = {best-arm identification, information-theoretic divergences, multi-armed bandit, pure exploration, sequential testing},
}

@inproceedings{Chen:2016:XST:2939672.2939785,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {XGBoost: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
}


%
% 2017
%

@inproceedings{Chaudhuri2017PACIO,
  title={PAC Identification of a Bandit Arm Relative to a Reward Quantile},
  author={Arghya Roy Chaudhuri and Shivaram Kalyanakrishnan},
  booktitle={AAAI},
  year={2017}
}


%
% 2018
%





%
% UNSORTED
%



   













@incollection{NIPS2015_6027,
title = {On Top-k Selection in Multi-Armed Bandits and Hidden Bipartite Graphs},
author = {Cao, Wei and Li, Jian and Tao, Yufei and Li, Zhize},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N.D. Lawrence and D.D. Lee and M. Sugiyama and R. Garnett and R. Garnett},
pages = {1036--1044},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@inproceedings{DBLP:conf/nips/ChenLKLC14,
  author    = {Shouyuan Chen and
               Tian Lin and
               Irwin King and
               Michael R. Lyu and
               Wei Chen},
  title     = {Combinatorial Pure Exploration of Multi-Armed Bandits},
  booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
               on Neural Information Processing Systems 2014, December 8-13 2014,
               Montreal, Quebec, Canada},
  pages     = {379--387},
  year      = {2014},
  timestamp = {Wed, 10 Dec 2014 21:34:12 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanTAS12,
  author    = {Shivaram Kalyanakrishnan and
               Ambuj Tewari and
               Peter Auer and
               Peter Stone},
  title     = {{PAC} Subset Selection in Stochastic Multi-armed Bandits},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning,
              (ICML)},
  year      = {2012},
}

@ARTICLE{2013arXiv1302.1611B,
   author = {{Bubeck}, S. and {Perchet}, V. and {Rigollet}, P.},
    title = "{Bounded regret in stochastic multi-armed bandits}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1302.1611},
 primaryClass = "math.ST",
 keywords = {Mathematics - Statistics Theory, Computer Science - Learning, Statistics - Machine Learning, 62L05},
     year = 2013,
    month = feb,
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{DBLP:conf/colt/AudibertBM10,
  author    = {Jean{-}Yves Audibert and
               S{\'{e}}bastien Bubeck and
               R{\'{e}}mi Munos},
  title     = {Best Arm Identification in Multi-Armed Bandits},
  booktitle = {{COLT} 2010 - The 23rd Conference on Learning Theory, Haifa, Israel,
               June 27-29, 2010},
  pages     = {41--53},
  year      = {2010},
  timestamp = {Tue, 19 Feb 2013 17:09:31 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/colt/KaufmannK13,
  author    = {Emilie Kaufmann and
               Shivaram Kalyanakrishnan},
  title     = {Information Complexity in Bandit Subset Selection},
  booktitle = {{COLT} 2013 - The 26th Annual Conference on Learning Theory, June
               12-14, 2013, Princeton University, NJ, {USA}},
  pages     = {228--251},
  year      = {2013},
  timestamp = {Thu, 11 Sep 2014 07:28:56 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Even-Dar:2006:AES:1248547.1248586,
 author = {Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
 title = {Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2006},
 volume = {7},
 month = dec,
 year = {2006},
 issn = {1532-4435},
 pages = {1079--1105},
 numpages = {27},
 acmid = {1248586},
 publisher = {JMLR.org},
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanS10,
  author    = {Shivaram Kalyanakrishnan and
               Peter Stone},
  title     = {Efficient Selection of Multiple Bandit Arms: Theory and Practice},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
               (ICML-10), June 21-24, 2010, Haifa, Israel},
  pages     = {511--518},
  year      = {2010},
  timestamp = {Fri, 12 Jun 2015 19:15:11 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{10.2307/2332286,
 author = {William R. Thompson},
 journal = {Biometrika},
 number = {3/4},
 pages = {285-294},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples},
 volume = {25},
 year = {1933}
}



@article{Burnetas1996122,
title = "Optimal Adaptive Policies for Sequential Allocation Problems ",
journal = "Advances in Applied Mathematics ",
volume = "17",
number = "2",
pages = "122 - 142",
year = "1996",
note = "",
issn = "0196-8858",
doi = "http://dx.doi.org/10.1006/aama.1996.0007",
author = "Apostolos N. Burnetas and Michael N. Katehakis"
}

@book{WaldsLemma,
title  = {Sequential Analysis},
author = {David Siegmund},
year = {1985},
}

@book{Cover:1991:EIT:129837,
 author = {Cover, Thomas M. and Thomas, Joy A.},
 title = {Elements of Information Theory},
 year = {1991},
 isbn = {0-471-06259-6},
 publisher = {Wiley-Interscience},
 address = {New York, NY, USA},
} 

@article{DBLP:journals/corr/CarpentierV15,
  author    = {Alexandra Carpentier and
               Michal Valko},
  title     = {Simple regret for infinitely many armed bandits},
  journal   = {CoRR},
  volume    = {abs/1505.04627},
  year      = {2015},
  timestamp = {Mon, 01 Jun 2015 14:13:54 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Escudero:2001:ULW:2387364.2387381,
 author = {Escudero, G. and M\`{a}rquez, L. and Rigau, G.},
 title = {Using LazyBoosting for Word Sense Disambiguation},
 booktitle = {The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems},
 year = {2001},
 
} 

@article{csiszar1984,
author = "Csiszar, Imre",
doi = "10.1214/aop/1176993227",
fjournal = "The Annals of Probability",
journal = "Ann. Probab.",
month = "08",
number = "3",
pages = "768--793",
publisher = "The Institute of Mathematical Statistics",
title = "Sanov Property, Generalized $I$-Projection and a Conditional Limit Theorem",
volume = "12",
year = "1984"
}

@article{Kaufmann:2016:CBI:2946645.2946646,
 author = {Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
 title = {On the Complexity of Best-arm Identification in Multi-armed Bandit Models},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1--42},
 numpages = {42},
 url = {http://dl.acm.org/citation.cfm?id=2946645.2946646},
 acmid = {2946646},
 publisher = {JMLR.org},
 keywords = {best-arm identification, information-theoretic divergences, multi-armed bandit, pure exploration, sequential testing},
}

@inproceedings{journals/jmlr/GarivierC11,
  added-at = {2013-11-25T00:00:00.000+0100},
  author = {Garivier, Aurélien and Cappé, Olivier},
  biburl = {http://www.bibsonomy.org/bibtex/2eaa70f360a064c34e95c79775fd5aaa8/dblp},
  booktitle = {COLT},
  crossref = {conf/colt/2011},
  editor = {Kakade, Sham M. and von Luxburg, Ulrike},
  ee = {http://www.jmlr.org/proceedings/papers/v19/garivier11a/garivier11a.pdf},
  interhash = {2f239ff7ecaa45d8963b3db2978c960e},
  intrahash = {eaa70f360a064c34e95c79775fd5aaa8},
  keywords = {dblp},
  pages = {359-376},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2015-06-19T12:47:52.000+0200},
  title = {The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp19.html#GarivierC11},
  volume = 19,
  year = 2011
}

@article{Lampret:2015:ADI:2828645.2828929,
 author = {Lampret, Vito},
 title = {Accurate Double Inequalities for Generalized Harmonic Numbers},
 journal = {Appl. Math. Comput.},
 issue_date = {August 2015},
 volume = {265},
 number = {C},
 month = aug,
 year = {2015},
 issn = {0096-3003},
 pages = {557--567},
 numpages = {11},
 url = {http://dx.doi.org/10.1016/j.amc.2015.04.128},
 doi = {10.1016/j.amc.2015.04.128},
 acmid = {2828929},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {11Y60, 33E20, 33F05, 40A25, 41A60, 65B10, 65B15, Approximation, Estimate, Euler-Maclaurin summation, Generalized harmonic number, Zeta-generalized-Euler-constant function, p-series},
}

@inproceedings{Jamieson:2016wd,
author = {Jamieson, Kevin and Haas, Daniel and Ben Recht},
title = {{The Power of Adaptivity in Identifying Statistical Alternatives}},
booktitle= {Advances on Neural Information Processing Systems (NIPS)},
year = {2016},
}

% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{YadLinear11,
  Title                    = {{Improved Algorithms for Linear Stochastic Bandits}},
  Author                   = {Abbasi-Yadkori, Y. and D.P{\'a}l and C.Szepesv{\'a}ri},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Abstract                 = {stochastic linear bandit, 'dual setting', action set that can vary in time, subgaussian assumption on the noise OFUL: regret bound slightly better than Rus-Tsi, interesting concentration arguments},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}


@Article{Agrawaletal89LBGene,
  Title                    = {{Asymptotically Efficient Adaptive Allocation Schemes for Controlled i.i.d. Processes: Finite Parameter Space}},
  Author                   = {Agrawal, R. and Teneketzis, D. and Anantharam, V.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1989},
  Pages                    = {258--267},
  Volume                   = {34(3)},

  Abstract                 = {A rapprocher de Graves et Lai pour la generalisation de la borne de Lai et Robbins, dans un cas plus simple (avec une preuve plus claire que l'on peut adapter !)},
  Owner                    = {kaufmann},
  Timestamp                = {2014.03.12}
}

@InProceedings{AGAISTAT13,
  Title                    = {{Further Optimal Regret Bounds for Thompson Sampling}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{AGContext13,
  Title                    = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{AGCOLT12,
  Title                    = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{Alonal15GraphFeedback,
  Title                    = {Online Learning with Feedback Graph: Beyond Bandits},
  Author                   = {Alon, N. and Cesa-Bianchi, N. and Dekel, O. and Koren, T.},
  Booktitle                = {Conference On Learning Theory (COLT)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@Article{Anantharam87,
  Title                    = {Asymptotically Efficient Allocation Rules for the Multiarmed Bandit Problem with Multiple Plays-Part I: I.I.D. Rewards},
  Author                   = {Anantharam, V. and Varaya, P. and Walrand, J.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1987},
  Number                   = {11},
  Pages                    = {968-976},
  Volume                   = {32},

  Owner                    = {emilie},
  Timestamp                = {2016.03.29}
}

@InProceedings{CsabaTracking,
  Title                    = {Active Learning in Multi-Armed Bandits},
  Author                   = {Antos, A. and Grover, V. and Szepesv\'{a}ri, C.},
  Booktitle                = {Algorithmic Learning Theory},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{Asmuthal09BOSS,
  Title                    = {{A Bayesian sampling approach to exploration in reinforcement learning}},
  Author                   = {Asmuth, J. and Li, L. and Littman, M.L. and Nouri, A. and Wingate, D.},
  Booktitle                = {{Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@Article{Audibertal10MOSS,
  Title                    = {{Regret Bounds and Minimax Policies under Partial Monitoring}},
  Author                   = {Audibert, J-Y. and Bubeck, S.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Audibertal11,
  Title                    = {{Minimax Policies for Combinatorial Prediction Games}},
  Author                   = {Audibert, J-Y. and Bubeck, S. and Lugosi, G.},
  Booktitle                = {{Conference On Learning Theory (COLT)}},
  Year                     = {2011},

  Abstract                 = {adversarial linear bandit when D={0,1}^d Lower bound in the dual setting : 0.005 d\sqrt(n) Lower bound in the setting where the loss of the adversary is simply bounded by 1 : 0.01d^{3/2}\sqrt{n} EXP2 algorithm as a generalization of COMBAND},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Article{Audibertal09UCBV,
  Title                    = {{Exploration-exploitation trade-off using variance estimates in multi-armed bandits}},
  Author                   = {Audibert, J-Y. and Munos, R. and Szepesv{\'a}ri, {Cs.}},
  Journal                  = {Theoretical Computer Science},
  Year                     = {2009},
  Number                   = {19},
  Volume                   = {410},

  File                     = {TCS08.pdf:http\://imagine.enpc.fr/publications/papers/TCS08.pdf:PDF}
}

@Article{Auer02,
  Title                    = {{Using Confidence bounds for Exploration Exploitation trade-offs}},
  Author                   = {Auer},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2002},
  Pages                    = {397--422},
  Volume                   = {3},

  Abstract                 = {- a variant of EXP3 for shifting bandit in the adversarial case [previous work of Auer on the adversarial bandit seems large] - LinRel algorithm for stochastic linear bandit (not under this name), states the Stochastic Linear Bandit Problem (?)},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.15}
}

@Article{Aueral02,
  Title                    = {{Finite-time analysis of the multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Fischer, P.},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {235--256},
  Volume                   = {47},

  Publisher                = {Springer}
}

@Article{Auer:al02EXP3,
  Title                    = {{The nonstochastic multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Freund, Y. and Schapire, R.},
  Journal                  = {SIAM Journal of Computing},
  Year                     = {2002},
  Pages                    = {48--77},
  Volume                   = {32(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Article{Balcan10Active,
  Title                    = {{The true sample complexity of active learning}},
  Author                   = {Balcan, M-F. and Hanneke, S. and {Wortman Voghan}, J.},
  Journal                  = {Machine Learning},
  Year                     = {2010},
  Pages                    = {111--139},
  Volume                   = {80}
}

@Article{Bechofer:54,
  Title                    = {{A single-sample multiple decision procedure for ranking means of normal populations with known variances}},
  Author                   = {Bechhofer, R.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1954},
  Pages                    = {16--39},
  Volume                   = {25},

  Abstract                 = {Static strategies for the gaussian case with known or unkown, similar or disimilar variances N=N\_1 + ... + N\_k samples. How to choose the N\_i (as small as possible) to achieve a given probability of error when the delta between the arms is known? (sufficient condition) Based on approximation of the probability of good ranking (a lower bound of the quantity is obtained in the least favorable 'slippage' configuration). The author provides a table that helps choosing N\_i in practise.},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@Book{Bechofer:al68,
  Title                    = {{Sequential identification and ranking procedures}},
  Author                   = {Bechhofer, Robert and Kiefer, Jack and Sobel, Milton},
  Publisher                = {The University of Chicago Press},
  Year                     = {1968},

  Abstract                 = {State the ranking and identification procedures with 'PCS1' probability conditions. No 'optimal' procedure, rather efficient procedures, based on fully uniform sampling: - for the identification problem: 'maximum a posteriori' with an uniform prior (possible to express in terms of likelihood) - for the ranking problem (for exponential families): use the same procedure, expressed in terms of gaps, and replace gaps by what they are in the Least Favorable (Slippage) configuration (heavily dependent on the delta parameter) Achieve the same garantee in terms of sample complexity as what can be done for a sequential multiple hypothesis testing based on K samples (and procedures for this purpose are hard to design!)},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@Article{Bellman:Bay56,
  Title                    = {{A problem in the sequential design of experiments}},
  Author                   = {Bellman, R.},
  Journal                  = {The indian journal of statistics},
  Year                     = {1956},
  Pages                    = {221--229},
  Volume                   = {16(3/4)},

  Abstract                 = {historical introduction general presentation of the bayesian bandit framework for two arms (discounted !) study the uncorelated case, 1/2 problem, in the discounted setting => discribe the stopping policy in terms of an index},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Bellman:54DP,
  Title                    = {{The theory of dynamic programming}},
  Author                   = {Bellman, R.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1954},
  Pages                    = {503--515},
  Volume                   = {60(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.28}
}

@Book{Berry:Fristedt85,
  Title                    = {{Bandit Problems. Sequential allocation of experiments}},
  Author                   = {Berry, D.A. and Fristedt, B.},
  Publisher                = {Chapman and Hall},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.21}
}

@Book{Bickel:Doksum,
  Title                    = {{Mathematical Statistics, Basic Ideas and Selected Topics}},
  Author                   = {Bickel, P. and Doksum, K.A.},
  Publisher                = {Prentice Hall},
  Year                     = {2001},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Book{Bishop06Laplace,
  Title                    = {{Pattern Recognition and Machine Learning}},
  Author                   = {Bishop, C.M.},
  Publisher                = {Springer-Verlag New York},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@InProceedings{OMS14,
  Title                    = {An analysis of optimistic, best-first search for minimax sequential decision making},
  Author                   = {Borsoniu, L. and Munos, R. and P{\'a}ll, E.},
  Booktitle                = {ADPRL14},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Book{Boucheronal13CI,
  Title                    = {{Concentration inequalities. A non asymptotic theory of independence.}},
  Author                   = {Boucheron, S., S. and Lugosi, G. and Massart, P},
  Publisher                = {Oxford University Press},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bradt:al56,
  Title                    = {{On sequential designs for maximizing the sum of n observations}},
  Author                   = {Bradt, R.N and Johnson, S.M. and Karlin, S.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1956},
  Pages                    = {1060--1074},
  Volume                   = {27(4)},

  Abstract                 = {contains the finite time Gittins indices ! bayesian finite-horizon framework - special case with a prior charging two values ('hypotheses' setting of Sonin) - product prior F(p)F(q) exactly solved for n=2 - solving the one-armed bandit with finite time exactly (approximation of Gittins indices) Link between the one-armed problem and the Gittins index : established by Gittins ! contient des relations entre indices finis},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Brezzi:Lai02,
  Title                    = {{Optimal learning and experimentation in bandit problems}},
  Author                   = {Brezzi, M. and Lai, T.},
  Journal                  = {Journal of Economics Dynamics and Control},
  Year                     = {2002},
  Pages                    = {87--108},
  Volume                   = {27},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Brezzi:LaiTech,
  Title                    = {{Incomplete learning fomr endogenous data in dynamic allocation}},
  Author                   = {Brezzi, M. and Lai, T.},
  Institution              = {Stanford University},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Brochu10Tuto,
  Title                    = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
  Author                   = {Brochu, E. and Cora, V.M. and {De Freitas}, N.},
  Institution              = {University of Bristish Columbia},
  Year                     = {2010},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@Article{SurveyMCTS12,
  Title                    = {A Survey of Monte Carlo Tree Search Methods},
  Author                   = {Browne, C. and Powley, E. and Whitehouse, D. and Lucas, S. and Cowling, P. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
  Journal                  = {IEEE Transactions on Computational Intelligence and AI in games,},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {1-49},
  Volume                   = {4},

  Owner                    = {emilie},
  Timestamp                = {2016.02.12}
}

@TechReport{Bubeck:LectOpt11,
  Title                    = {{Introduction to Online Optimization}},
  Author                   = {Bubeck, S.},
  Institution              = {Lecture Notes, Princeton University},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@PhdThesis{Bubeck:Thesis,
  Title                    = {{Jeux de bandits et fondation du clustering}},
  Author                   = {Bubeck, S.},
  School                   = {Universit{\'e} de Lille 1},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bubeck:Survey12,
  Title                    = {{Regret analysis of stochastic and nonstochastic multi-armed bandit problems}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N.},
  Journal                  = {Fondations and Trends in Machine Learning},
  Year                     = {2012},
  Pages                    = {1--122},
  Volume                   = {5(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.13}
}

@InProceedings{Bubeck:al12,
  Title                    = {{Towards Minimax Policies for Online Linear Opimization with Bandit Feedback}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N. and Kakade, S.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Abstract                 = {adversarial linear bandit EXP2 with John distribution (intractable) minimax optimal when A is finite Efficient Miror-Descent based algorithm for two situation (combinatorial case and euclidian ball) For A and Z as the euclidian ball, we get a upper bound on the regret of sqrt(dn) -> There is no current lower bound for given A and Z!},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Article{BG13,
  Title                    = {Optimal Discovery with Probabilistic Expert Advice: Finite Time Analysis and Macroscopic Optimality},
  Author                   = {Sébastien Bubeck and Damien Ernst and Aurélien Garivier},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {Feb. 2013},
  Pages                    = {601--623},
  Volume                   = {14}
}

@InProceedings{BubeckLiu:13,
  Title                    = {{Prior-free and prior-dependent regret bounds for Thompson Sampling}},
  Author                   = {Bubeck, S. and Liu, C.-Y.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@Article{Bubeckal11,
  Title                    = {{Pure Exploration in Finitely Armed and Continuous Armed Bandits}},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G.},
  Journal                  = {Theoretical Computer Science 412, 1832-1852},
  Year                     = {2011},
  Pages                    = {1832--1852},
  Volume                   = {412},

  Abstract                 = {algorithm minimizing the simple regret at round n correspond to a different set of application : you don't care making error in the exploration phase and just have to make a good recomandation for the arm in the end -> pure exploration, interesting applications (Marjorie?) forecaster : pair of an allocation (how to deal with exploration) and a recomandation (what you advice at a given stage if you have to stop exploring) -> (or try to) version of the pure exploration problem a strategy that has low cummulative regret (for its exploration phase) has a simple regret that is lower bounded ! lower bound for the simple regret (Bernoulli) : exponential decay, unlike what is achieved with an UCB exploration upper bound on the simple regret for strategy including UCB and the uniform exploration (which turns to be optimal coupled with an recommandation based on the empirical mean)},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@Article{Bubeck11Xarmed,
  Title                    = {X-armed bandits},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G. and Szepesv\'{a}ri, C.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {1587-1627},
  Volume                   = {12},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{BPR13,
  Title                    = {{Bounded regret in stochastic multi-armed bandits}},
  Author                   = {Bubeck, S. and Perchet, V. and Rigollet, P.},
  Booktitle                = {{Proceedings of the 26th Conference On Leaning Theory}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{Bubeck:alMult13,
  Title                    = {{Multiple Identifications in multi-armed bandits}},
  Author                   = {Bubeck, S. and Wang, T. and Viswanathan, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Abstract                 = {An algorithm for finding the m best arms in a pure-exploration setting with known horizon n upper bound the probability of error at time t (no matching lower bound) Successive Acepts and Rejects algorithms : suprinsingly enough, the Successive Reject does not work !},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@Article{Bull11EI,
  Title                    = {{Convergence Rates of Efficient Global Optimization Algorithms}},
  Author                   = {Bull, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {2879--2904},
  Volume                   = {12},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@Article{BurnKat03OneArmed,
  Title                    = {{Asymptotic Bayes Analysis for the finite horizon one armed bandit problem}},
  Author                   = {Burnetas, A. and Katehakis, M.},
  Journal                  = {Probability in the Engineering and Informational Sciences},
  Year                     = {2003},
  Pages                    = {53--82},
  Volume                   = {17},

  Abstract                 = {contains an asymptotic resolution of the B\_lambda problem for two arms in the exponential family ! draws no parallel with Gittins index proposes an alternative exploration rate},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.21}
}

@Article{Burn:Kat:MDP97,
  Title                    = {{Optimal adaptive policies for {M}arkov decision processes}},
  Author                   = {Burnetas, A.N. and Katehakis, M.N.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {1997},
  Pages                    = {222--255},

  Publisher                = {Institute for Operations Research and the Management Sciences}
}

@Article{BurnKat96,
  Title                    = {{Optimal adaptive policies for sequential allocation problems}},
  Author                   = {Burnetas, A.N and Katehakis, M.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1996},
  Pages                    = {122--142},
  Volume                   = {17(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{KLUCBJournal,
  Title                    = {{{K}ullback-{L}eibler upper confidence bounds for optimal sequential allocation}},
  Author                   = {Capp{\'e}, O. and Garivier, A. and Maillard, O-A. and Munos, R. and Stoltz, G.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {1516--1541},
  Volume                   = {41(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.31}
}

@InProceedings{Marc12SideInfo,
  Title                    = {Levaraging Side Observations in Stochastic Bandits},
  Author                   = {Caron, S. and Kveton, B. and Lelarge, M. and Bhagat, S.},
  Booktitle                = {Conference on Uncertainty in Artificial Intelligence (UAI)},
  Year                     = {2012},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@InProceedings{carpentier2015simple,
  Title                    = {{Simple regret for infinitely many armed bandits}},
  Author                   = {Carpentier, Alexandra and Valko, Michal},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2015},

  Abstract                 = {We consider a stochastic bandit problem with infinitely many arms. In this setting, the learner has no chance of trying all the arms even once and has to dedicate its limited number of samples only to a certain number of arms. All previous algorithms for this setting were designed for minimizing the cumulative regret of the learner. In this paper, we propose an algorithm aiming at minimizing the simple regret. As in the cumulative regret setting of infinitely many armed bandits, the rate of the simple regret will depend on a parameter {\$}\backslashbeta{\$} characterizing the distribution of the near-optimal arms. We prove that depending on {\$}\backslashbeta{\$}, our algorithm is minimax optimal either up to a multiplicative constant or up to a {\$}\backslashlog(n){\$} factor. We also provide extensions to several important cases: when {\$}\backslashbeta{\$} is unknown, in a natural setting where the near-optimal arms have a small variance, and in the case of unknown time horizon.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{Comband12,
  Title                    = {{Combinatorial Bandits}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Journal                  = {Journal of Computer and System Sciences},
  Year                     = {2012},
  Pages                    = {1404--1422},
  Volume                   = {78},

  Abstract                 = {adversarial linear bandit with D={0,1}^d COMBAND algorithm (not always enjoying a good regret, depends on an exploration distribution) a lot of funny example},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Book{PLG06,
  Title                    = {{Prediction, Learning and Games}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Publisher                = {Cambridge University Press},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@InProceedings{Chandra14COLT,
  Title                    = {{Finding a most biaised coin with fewest flips}},
  Author                   = {Chandrasekaran, K. and Karp, R.},
  Booktitle                = {{Proceeding of the 27th Conference on Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{ChangLai87,
  Title                    = {{Optimal stopping and dynamic allocation}},
  Author                   = {Chang, F. and Lai, T.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1987},
  Pages                    = {829--853},
  Volume                   = {19},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@InProceedings{LiChapelle11,
  Title                    = {{An empirical evaluation of Thompson Sampling}},
  Author                   = {Chapelle, O. and Li, L.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@Article{Chapelleetal14Ad,
  Title                    = {{Simple and scalable response prediction for display advertising.}},
  Author                   = {Chapelle, O. and Manavoglu, E. and Rosales, R.},
  Journal                  = {Transactions on Intelligent Systems and Technology},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{Chen16OptimalAlt,
  Title                    = {Towards Instance Optimal Bounds for Best Arm Identification},
  Author                   = {Chen, L. and J. Li and M. Qiao},
  Journal                  = {arXiv:1608.06031},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2017.01.13}
}

@InProceedings{Chen14ComBAI,
  Title                    = {{Combinatorial Pure Exploration of Multi-Armed Bandits}},
  Author                   = {Chen, S. and Lin, T. and King, I. and Lyu, M. and Chen, W.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014}
}

@TechReport{Chernoff:Tech67,
  Title                    = {{Optimal stochastic control}},
  Author                   = {Chernoff, H.},
  Institution              = {Stanford, California},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.05}
}

@InProceedings{Chernoff67,
  Title                    = {{Sequential models for clinical trials}},
  Author                   = {Chernoff, H.},
  Booktitle                = {{Fifth Berkeley Symposium on Mathematical Statistics and Probability}},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@Article{Chernoff59,
  Title                    = {{Sequential design of Experiments}},
  Author                   = {Chernoff, H.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1959},
  Number                   = {3},
  Pages                    = {755--770},
  Volume                   = {30}
}

@Article{Chernoff:Ray65,
  Title                    = {{A Bayes sequential sampling inspection plan}},
  Author                   = {Chernoff, H. and Ray, S.N.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1965},
  Pages                    = {1387--1407},
  Volume                   = {36},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@Book{Cheung11Book,
  Title                    = {Dose finding with the Continual Reassessment Method},
  Author                   = {Cheung, Y.K.},
  Publisher                = {Chapman and Hall},
  Year                     = {2011},

  Owner                    = {emilie},
  Timestamp                = {2016.11.03}
}

@InProceedings{LinUCB11,
  Title                    = {{Contextual Bandits with Linear Payoff Functions}},
  Author                   = {Chu, W. and Li, L. and Reyzin, L. and Schapire, R.},
  Booktitle                = {{Proceedings of the 14th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Article{ClopperPearson34,
  Title                    = {{The use of confidence of fiducial limits illustration in the case of the binomial}},
  Author                   = {Clopper, C.J. and Pearson, E.S.},
  Journal                  = {Biometrika},
  Year                     = {1934},
  Pages                    = {404--413},
  Volume                   = {26}
}

@Article{Combes15JSAC,
  Title                    = {{Dynamic Rate and Channel Selection in Cognitive Radio Systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Journal                  = {IEEE Journal on Selected Area in Communication},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{Combes14COLT,
  Title                    = {Unimodal bandits: Regret lower bounds and optimal algorithms},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@TechReport{Combes14Unimodal,
  Title                    = {{Unimodal Bandits without Smoothness}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Year                     = {2014},

  Booktitle                = {{arXiv:1406.7447}}
}

@Conference{Combes14802,
  Title                    = {{Optimal rate sampling in 802.11 systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A. and Yun, D. and Ok, J. and Yi, Y.},
  Booktitle                = {{IEEE INFOCOM}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{CombUCB15,
  Title                    = {Combinatorial bandits revisited},
  Author                   = {Combes, R. and Talebi, S. and Prouti{\`e}re, A. and Lelarge, M.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.30}
}

@InProceedings{Vayatis13GP,
  Title                    = {{Parallel Gaussian Process Optimization with Upper Confidence Bounds and Pure Exploration}},
  Author                   = {Contal, E. and Buffoni, D. and Vayatis, N.},
  Booktitle                = {{Proceedings of the European Conference on Machine Learning}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.17}
}

@InProceedings{Contal15Chaining,
  Title                    = {Optimization for Gaussian Processes via Chaining},
  Author                   = {Contal, E. and Malherbe, C. and Vayatis, N.},
  Booktitle                = {NIPS workshop on Bayesian Optimization},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@Book{Cover:Thomas,
  Title                    = {{Elements of Information Theory (2nd Edition)}},
  Author                   = {Cover, T. and Thomas, J.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.29}
}

@InProceedings{Danial08,
  Title                    = {{Stochastic Linear Optimization under Bandit Feedback}},
  Author                   = {Dani, V. and Hayes, T.P. and Kakade, S.M.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2008},
  Pages                    = {355--366},

  Abstract                 = {stochastic linear bandit, dual setting algo Confidence Ball (L1 and L2) Minimax Lower bound d*sqrt(n) (rather adversarial) on the hypercube Upper bound in high probability on the regret - problem dependant when Delta>0 - problem independant},
  Journal                  = {Conference On Learning Theory (COLT)},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}

@InProceedings{Danial07,
  Title                    = {{The Price of Bandit Information in Online Optimization}},
  Author                   = {Dani, V. and Hayes, T. and Kakade, S.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2007},

  Abstract                 = {adversarial linear bandit (oblivious?) mention of a lower bound (not very clear, see their paper from 2008) (on the hypercube) Geometric Hedge algorithm},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Article{DeLaPenaal04,
  Title                    = {{Self-Normalized Processes: Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {{De La Pena}, V. and Klass, M. and Lai, T.L.},
  Journal                  = {The Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DeLaPenaal09Book,
  Title                    = {{Self-normalized processes. Limit Theory and Statistical applications}},
  Author                   = {{De La Pena}, V.H. and Lai, T.L. and Q., Shao},
  Publisher                = {Springer},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DemboZeitouni,
  Title                    = {{Large Deviations Techniques and Applications, 2nd Edition}},
  Author                   = {Dembo, Amir and Zeitouni, Ofer},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.23}
}

@Article{Romaric14,
  Title                    = {{Efficient Eigen-updating for Spectral Graph Clustering}},
  Author                   = {Dhanjal, C. and Gaudel, R. and Cl{\'e}mencon, S.},
  Journal                  = {arXiv:1301.1318},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Conference{SpherCov06,
  Title                    = {{Covering spheres and balls with smaller balls}},
  Author                   = {Dumer, I.},
  Booktitle                = {{ISIT}},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Durand14AAAI,
  Title                    = {{Thompson Sampling for Combinatorial Bandits and Its Application to Online Feature Selection}},
  Author                   = {Durand, A. and Gagn{\'e}, C.},
  Booktitle                = {{AAAI-14 Workshop on Sequential Decision-Making with Big Data}},
  Year                     = {2014}
}

@Book{Durrett10,
  Title                    = {{Probability: Theory and Examples}},
  Author                   = {Durrett, R.},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.17}
}

@Article{Eckles14TSBootstrap,
  Title                    = {Thompson Sampling with the online bootstrap},
  Author                   = {Eckles, D. and Kaptein, M.},
  Journal                  = {arXiv:1410.4009},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.10.13}
}

@Article{EvenDaral06,
  Title                    = {{Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems}},
  Author                   = {Even-Dar, E. and Mannor, S. and Mansour, Y.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1079--1105},
  Volume                   = {7},

  Abstract                 = {Pure exploration problem of finding the best arm in a PAC setting (with a level epsilon of tolerance) Several algorithms are proposed, with successive elimination sometimes},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@Article{Feldman62,
  Title                    = {{Contributions to the ''two-armed bandit''}},
  Author                   = {Feldman, D.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1962},
  Pages                    = {947--956},
  Volume                   = {33(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@PhdThesis{filippi10,
  Title                    = {{Optimistic strategies in Reinforcement Learning \emph{(in French)}}},
  Author                   = {Filippi, S.},
  School                   = {Telecom ParisTech},
  Year                     = {2010},

  Url                      = {http://tel.archives-ouvertes.fr/tel-00551401}
}

@InProceedings{allerton10,
  Title                    = {{Optimism in Reinforcement Learning and {K}ullback-{L}eibler Divergence}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Allerton Conference on Communication, Control, and Computing}},
  Year                     = {2010},

  Address                  = {Monticello, US},

  Eprint                   = {1004.5229}
}

@InProceedings{Filippi:GLM10,
  Title                    = {{Parametric Bandits : The Generalized Linear case}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A. and Szepesv{\'a}ri, C.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@InProceedings{Fonteneaual13,
  Title                    = {{An optimistic posterior sampling strategy for Bayesian reinforcement learning}},
  Author                   = {Fonteneau, R. and Korda, N. and Munos, R.},
  Booktitle                = {{Workshop on Bayesian Optimization, NIPS}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@TechReport{Frostig:Weiss99,
  Title                    = {{Four proofs of {G}ittins' multiarmed bandit theorem}},
  Author                   = {Frostig, E. and Weiss, G.},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{Gabillon:al12,
  Title                    = {{Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence}},
  Author                   = {Gabillon, V. and Ghavamzadeh, M. and Lazaric, A.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.06}
}

@InProceedings{Aurelien13,
  Title                    = {{Informational Confidence Bounds for Self-Normalized Averages and Applications}},
  Author                   = {Garivier, A.},
  Booktitle                = {{IEEE Information Theory Workshop}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.20}
}

@InProceedings{AOKLUCB,
  Title                    = {{The {KL-UCB} algorithm for bounded stochastic bandits and beyond}},
  Author                   = {Garivier, A. and Capp{\'e}, O.},
  Booktitle                = {{Proceedings of the 24th Conference on Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{GK16,
  Title                    = {Optimal Best Arm Identification with Fixed Confidence},
  Author                   = {Garivier, Aur{\'e}lien and Kaufmann, Emilie},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016}
}

@InProceedings{GKK16,
  Title                    = {Maximin Action Identification: A New Bandit Framework for Games},
  Author                   = {Garivier, A. and Kaufmann, E. and Koolen, W.M.},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory (to appear)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.05.25}
}

@InProceedings{GKL16,
  Title                    = {On Explore-Then-Commit strategies},
  Author                   = {Garivier, A. and Kaufmann, E. and Lattimore, T.},
  Booktitle                = {Advances in Neural Processing Systems (NIPS)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2017.01.15}
}

@Article{GL11,
  Title                    = {Context Tree Selection: A Unifying View},
  Author                   = {Aurélien Garivier and Florencia Leonardi},
  Journal                  = { Stochastic Processes and their Applications},
  Year                     = {Nov. 2011},
  Number                   = {11},
  Pages                    = {2488--2506},
  Volume                   = {121},

  Arxiv                    = {1011.2424}
}

@Article{GMS16,
  Title                    = {Explore First, Exploit Next: The True Shape of Regret in Bandit Problems},
  Author                   = {Garivier, Aur{\'e}lien and M{\'e}nard, Pierre and Stoltz, Gilles},
  Journal                  = {arXiv preprint arXiv:1602.07182},
  Year                     = {2016}
}

@InProceedings{GarivierMoulines11,
  Title                    = {{On Upper-Confidence Bound Policies for Switching Bandit Problems}},
  Author                   = {Garivier, A. and Moulines, E.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GinebraClayton99,
  Title                    = {{Small-sample performance of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Journal                  = {Journal of Statistical Planning and Inference},
  Year                     = {1999},
  Pages                    = {107--122},
  Volume                   = {79(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@TechReport{GinebraClayton94TechReportFreq,
  Title                    = {{Small-sample frequentist properties of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Institution              = {University of Wisconsin},
  Year                     = {1994},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.05.31}
}

@Article{Gittins79,
  Title                    = {{Bandit processes and dynamic allocation indices}},
  Author                   = {Gittins, J.C.},
  Journal                  = {Journal of the Royal Statistical Society, Series B},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {148--177},
  Volume                   = {41},

  Keywords                 = {bandit},
  Publisher                = {JSTOR}
}

@Book{GittinsBook11,
  Title                    = {{Multi-armed bandit allocation indices (2nd Edition)}},
  Author                   = {Gittins, J. and Glazebrook, K. and Weber, R.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Gittins:Jones79,
  Title                    = {{A dynamic allocation index for the discounted multiarmed bandit problem}},
  Author                   = {Gittins, J.C. and Jones, D.M.},
  Journal                  = {Biometrika},
  Year                     = {1979},
  Number                   = {3},
  Pages                    = {561--565},
  Volume                   = {66},

  Keywords                 = {bandit},
  Publisher                = {Biometrika Trust}
}

@InProceedings{Gittins:Jones74,
  Title                    = {{A dynamic allocation index for the sequential design of experiments}},
  Author                   = {Gittins, J. and Jones, D.M.},
  Booktitle                = {{Progress in Statistics (proceedings of the 1972 European Meeting of Statisticians)}},
  Year                     = {1974},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{GlynnJuneja04,
  Title                    = {A large deviations perspective on ordinal optimization},
  Author                   = {Glynn, P. and Juneja, S.},
  Booktitle                = {Proceedings of the 2004 Winter Simulation Conference (IEEE)},
  Year                     = {2004},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@InProceedings{Gopalan14TSComplex,
  Title                    = {{Thompson Sampling for Complex Online Problems}},
  Author                   = {Gopalan, A. and Mannor, S. and Mansour, Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{GranmoBLA,
  Title                    = {{Solving two-armed Bernoulli Bandit Problems using a Bayesian Learning Automaton}},
  Author                   = {Granmo, O.C.},
  Journal                  = {International Journal of Intelligent Computing and Cybernetics},
  Year                     = {2010},
  Pages                    = {207--234},
  Volume                   = {3(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GravesLai97,
  Title                    = {{Asymptotically Efficient adaptive choice of control laws in controlled markov chains}},
  Author                   = {Graves, T.L. and Lai, T.L.},
  Journal                  = {SIAM Journal on Control and Optimization},
  Year                     = {1997},
  Pages                    = {715--743},
  Volume                   = {35(3)},

  Abstract                 = {generalisation de la borne de Lai et Robbins: - � des bandits om on a des informations pr�cise sur les param�tre des bras (e.g. bounded regret) - aux restless bandits (trop simple?) - aux switching bandits},
  Owner                    = {kaufmann},
  Timestamp                = {2013.07.15}
}

@InProceedings{Grill16TrailBlazer,
  Title                    = {Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning},
  Author                   = {Grill, J.-B. and Valko, M. and Munos, R.},
  Booktitle                = {Neural Information Processing Systems (NIPS)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@InProceedings{grill2015black-box,
  Title                    = {{Black-box optimization of noisy functions with unknown smoothness}},
  Author                   = {Grill, Jean-Bastien and Valko, Michal and Munos, R{\'{e}}mi},
  Booktitle                = {Advances on Neural Information Processing Systems (NIPS)},
  Year                     = {2015},

  Abstract                 = {We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO's performance, which shows that its error after n evaluations is at most a factor of sqrt(ln n) away from the error of the best known optimization algorithms using the knowledge of the smoothness.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Guha14TSweird,
  Title                    = {{Stochastic Regret Minimization via Thompson Sampling}},
  Author                   = {Guha, S. and Munagala, K.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{HeidrichMeisneral09,
  Title                    = {{{H}oeffding and {B}ernstein Races for Selecting Policies in Evolutionary Direct Policy Search}},
  Author                   = {Heidrich-Meisner, V. and Igel, C.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2012.10.01}
}

@Article{Hoeffding63,
  Title                    = {{Probability inequalities for sums of bounded random variables}},
  Author                   = {Hoeffding, W.},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1963},
  Pages                    = {13:30},
  Volume                   = {58},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.19}
}

@InProceedings{Hoffmanal14,
  Title                    = {{On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning}},
  Author                   = {Hoffman, M. and Shahriari, B. and de Freitas, N.},
  Booktitle                = {{Proceedings of the 17th International Conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@InProceedings{HondaTakemura10,
  Title                    = {{An Asymptotically Optimal Bandit Algorithm for Bounded Support Models}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 23rd Conference on Learning Theory}},
  Year                     = {2010},
  Editor                   = {Kalai, T. and Mohri, M.}
}

@InProceedings{HondaTakemura14TS,
  Title                    = {{Optimality of Thompson Sampling for Gaussian Bandits depends on priors}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 17th conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{Auer:UCRL10,
  Title                    = {{Near-Optimal regret bounds for reinforcement learning}},
  Author                   = {Jaksch, T. and Ortner, R. and Auer, P.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {1563--1600},
  Volume                   = {11},

  Owner                    = {kaufmann},
  Timestamp                = {2013.02.28}
}

@Article{Marjorie15,
  Title                    = {{Sequential design of computer experiments for the assessment of fetus exposure to electromagnetic fields}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Journal                  = {Technometrics},
  Year                     = {2015},
  Volume                   = {to appear},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Jala:al12,
  Title                    = {{Sequential design of computer experiments for parameter estimation}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Booktitle                = {{EUSIPCO}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{Jamieson15Duel,
  Title                    = {{Sparse Dueling Bandits}},
  Author                   = {Jamieson, K. and Katariya, S. and Deshpande, A. and Nowak, R.},
  Booktitle                = {{Proceedings of the 18th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2015.02.07}
}

@InProceedings{Jamiesonal14LILUCB,
  Title                    = {{lil'{UCB}: an Optimal Exploration Algorithm for Multi-Armed Bandits}},
  Author                   = {Jamieson, K. and Malloy, M. and Nowak, R. and Bubeck, S.},
  Booktitle                = {{Proceedings of the 27th Conference on Learning Theory}},
  Year                     = {2014},

  Journal                  = {arXiv:1312.7308},
  Owner                    = {kaufmann},
  Timestamp                = {2014.01.22}
}

@Article{Jeffreys46,
  Title                    = {{An invariant form for prior probability in estimation problems}},
  Author                   = {Jeffreys, H.},
  Journal                  = {Proceedings of the Royal Society of London, Serie A.},
  Year                     = {1946},
  Pages                    = {453--461},
  Volume                   = {286},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Article{Jennisonal84,
  Title                    = {{Asymptotically optimal procedures for sequential adaptive selection of the best of several normal means}},
  Author                   = {Jennison, Christopher and Johnstone, Iain M. and Turnbull, Bruce W.},
  Journal                  = {Statistical Decision Theory and Related Topics III},
  Year                     = {1982},
  Pages                    = {55--86},
  Volume                   = {2},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.24}
}

@Article{Jones:alEI98,
  Title                    = {{Efficient Global Optimization of Expensive Black-Box Functions}},
  Author                   = {Jones, Donal R. and Schonlau, Matthias and Welch, William},
  Journal                  = {Journal of Global Optimization},
  Year                     = {1998},
  Pages                    = {455--492},
  Volume                   = {13(4)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{JunNowak16,
  Title                    = {Anytime exploration for Multi-armed Bandits using Confidence Information},
  Author                   = {Jun, K-W and Nowak, R.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@PhdThesis{Shivaram:PHD,
  Title                    = {{Learning Methods for Sequential Decision Making with Imperfect Representations}},
  Author                   = {Kalyanakrishnan, S.},
  School                   = {Departement of Computer Science, The University of Texas at Austin},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.19}
}

@InProceedings{Shivaram:al10,
  Title                    = {{Efficient Selection in Multiple Bandit Arms: Theory and Practice}},
  Author                   = {Kalyanakrishnan, S. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.09.05}
}

@InProceedings{Shivaramal12,
  Title                    = {{{PAC} subset selection in stochastic multi-armed bandits}},
  Author                   = {Kalyanakrishnan, S. and Tewari, A. and Auer, P. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@InProceedings{Karnin:al13,
  Title                    = {{Almost optimal Exploration in multi-armed bandits}},
  Author                   = {Karnin, Z. and Koren, T. and Somekh, O.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.21}
}

@Article{KatRob:95Gauss,
  Title                    = {{Sequential choice from several populations}},
  Author                   = {Katehakis, M. and Robbins, H.},
  Journal                  = {Proceedings of the National Academy of Science},
  Year                     = {1995},
  Pages                    = {8584--8585},
  Volume                   = {92},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.25}
}

@Article{AOS16,
  Title                    = {On Bayesian Index Policies for Sequential Resource Allocation},
  Author                   = {Kaufmann, E.},
  Journal                  = {Preprint arXiv:1601.01190},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.02.01}
}

@PhdThesis{MaThese,
  Title                    = {{Analyse de strat{\'e}gies bay{\'e}siennes et fr{\'e}quentistes pour l'allocation s{\'e}quentielle de ressources}},
  Author                   = {Kaufmann, E.},
  Year                     = {2014},

  Organization             = {Telecom ParisTech}
}

@Article{JMLR15,
  Title                    = {{On the Complexity of Best Arm Identification in Multi-Armed Bandit Models}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {1-42},
  Volume                   = {17},

  Booktitle                = {{arXiv:1407.4443}},
  Owner                    = {kaufmann},
  Timestamp                = {2014.07.15}
}

@InProceedings{COLT14,
  Title                    = {{On the Complexity of A/B Testing}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@InProceedings{AISTATS12,
  Title                    = {{On {B}ayesian {U}pper-{C}onfidence {B}ounds for Bandit Problems}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 15th conference on Artificial Intelligence and Statistics}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{ESAIM17,
  Title                    = {Learning the distribution with largest mean: two bandit frameworks},
  Author                   = {Kaufmann, E. and Garivier, A.},
  Journal                  = {arXiv:1702.00001},
  Year                     = {2017},

  Owner                    = {emilie},
  Timestamp                = {2017.02.20}
}

@InProceedings{COLT13,
  Title                    = {{Information complexity in bandit subset selection}},
  Author                   = {Kaufmann, E. and Kalyanakrishnan, S.},
  Booktitle                = {{Proceeding of the 26th Conference On Learning Theory.}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{ALT12,
  Title                    = {{Thompson Sampling : an Asymptotically Optimal Finite-Time Analysis}},
  Author                   = {Kaufmann, E. and Korda, N. and Munos, R.},
  Booktitle                = {{Proceedings of the 23rd conference on Algorithmic Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@Book{RPS,
  Title                    = {{Requiem pour {S}tanley}},
  Author                   = {Kaufmann, S.},
  Publisher                = {Editions Lulu},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.08.24}
}

@InProceedings{Kleinberg04Infinite,
  Title                    = {Nearly tight bounds for the continuum-armed bandit problem},
  Author                   = {Kleinberg, R.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2004},

  Owner                    = {emilie},
  Timestamp                = {2017.02.20}
}

@InProceedings{Kleinberg08Infinite,
  Title                    = {Multi-armed bandit in metric spaces},
  Author                   = {Kleinberg, R. and Slivkins, A. and Upfal, E.},
  Booktitle                = {Proceedings of the 40th ACM Symposium on Theory of Computing},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2017.02.20}
}

@Conference{Kocak14SpectralTS,
  Title                    = {{Spectral Thompson Sampling}},
  Author                   = {Koc{\'a}k, T. and Valko, M. and Munos, R. and Agrawal, S.},
  Booktitle                = {{International Conference on Machine Learning}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{Kocsis2006,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, Levente and Szepesv\'{a}ri, Csaba},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Doi                      = {10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12},
  Url                      = {http://dx.doi.org/10.1007/11871842_29}
}

@InProceedings{KocsisBBMCP06,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, L. and Szepesv\'{a}ri, C.},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Comment-doi              = {10.1007/11871842_29},
  Comment-url              = {http://dx.doi.org/10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12}
}

@InProceedings{NIPS13,
  Title                    = {{Thompson Sampling for 1-dimensional Exponential family bandits}},
  Author                   = {Korda, N. and Kaufmann, E. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@InProceedings{Krause:11Context,
  Title                    = {{Contextual Gaussian Process Bandit Optimization}},
  Author                   = {Krause, A. and Ong, C.S.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@Article{Lai:SeqTest88,
  Title                    = {{Nearly Optimal Sequential Tests for Composite Hypotheses}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1988},
  Pages                    = {856--886},
  Volume                   = {16(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.12}
}

@Article{Lai88,
  Title                    = {{Boundary Crossing problems for samples means}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {1988},
  Pages                    = {375--396},
  Volume                   = {16(1)},

  Abstract                 = {present a general concentration inequality in terms of KL-divergence that is useful in a asymoptotic analysis for 'KL-UCB' provided in Lai87 and also for sequential hypothese testing},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.19}
}

@Article{Lai87,
  Title                    = {{Adaptive treatment allocation and the multi-armed bandit problem}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1987},
  Pages                    = {1091--1114},
  Volume                   = {15(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{LaiRobbins85bandits,
  Title                    = {{Asymptotically efficient adaptive allocation rules}},
  Author                   = {Lai, T.L. and Robbins, H.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Date-modified            = {2010-02-02 03:14:31 -0700},
  Publisher                = {Elsevier}
}

@Article{L16,
  Title                    = {Regret Analysis of the Anytime Optimally Confident {UCB} Algorithm},
  Author                   = {Tor Lattimore},
  Journal                  = {CoRR},
  Year                     = {2016},
  Volume                   = {abs/1603.08661},

  Bibsource                = {dblp computer science bibliography, http://dblp.org},
  Biburl                   = {http://dblp.uni-trier.de/rec/bib/journals/corr/Lattimore16},
  Timestamp                = {Sat, 02 Apr 2016 11:49:48 +0200},
  Url                      = {http://arxiv.org/abs/1603.08661}
}

@Article{Tor15Gittins,
  Title                    = {Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits},
  Author                   = {Lattimore, T.},
  Journal                  = {arXiv:1511.06014},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.27}
}

@Article{LaurentMassart00,
  Title                    = {{Adaptive estimation of a quadratic functional by model selection}},
  Author                   = {Laurent, B. and Massart, P},
  Journal                  = {Annals of Statistics},
  Year                     = {2000},
  Pages                    = {1302--1338},
  Volume                   = {28(5)},

  Abstract                 = {gives an upper bound on the quantile of a chi square distribution},
  Owner                    = {kaufmann},
  Timestamp                = {2013.11.28}
}

@InProceedings{Lelarge13Spectrum,
  Title                    = {{Spectrum Bandit Optimization}},
  Author                   = {Lelarge, M. and Prouti{\`e}re, A. and Talebi, S.},
  Booktitle                = {{ITW}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{LevinLeu:08AR,
  Title                    = {{On a Conjecture of Bechhofer, Kiefer, and Sobel for the Levin-Robbins-Leu Binomial Subset Selection Procedures}},
  Author                   = {Levin, B. and Leu, C.},
  Journal                  = {Sequential Analysis},
  Year                     = {2008},
  Pages                    = {106--125},
  Volume                   = {27},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@InProceedings{LiChapelle:OpenPb,
  Title                    = {{Open Problem: Regret Bounds for Thompson Sampling}},
  Author                   = {Li, L. and Chapelle, O.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@Article{Jamieson16JHyperOpt,
  Title                    = {Efficient Hyperparameter Optimization and Infinitely Many Armed Bandits},
  Author                   = {Li, L. and Jamieson, K. and DeSalvo G. and Rostamizadeh, A. and Talwalkar, A.},
  Journal                  = {arXiv:1603.06560v1},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@Article{LiuLi15,
  Title                    = {On the prior sensitivity of Thompson Sampling},
  Author                   = {Liu, C.-Y. and Li, L.},
  Journal                  = {arXiv:1506.03378},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@InProceedings{LocatelliGC16,
  Title                    = {An optimal algorithm for the Thresholding Bandit Problem},
  Author                   = {Andrea Locatelli and
 Maurilio Gutzeit and
 Alexandra Carpentier},
  Booktitle                = {Proceedings of the 33nd International Conference on Machine Learning,
 {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  Year                     = {2016},
  Pages                    = {1690--1698}
}

@InProceedings{Combes14Lip,
  Title                    = {{Lipschitz Bandits: Regret lower bounds and optimal algorithms}},
  Author                   = {Magureanu, S. and Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {{Proceedings on the 27th Conference On Learning Theory}},
  Year                     = {2014}
}

@InProceedings{Maillard:al11KLUCB,
  Title                    = {{A Finite-Time Analysis of Multi-armed Bandits Problems with {K}ullback-{L}eibler Divergences}},
  Author                   = {Maillard, O-A. and Munos, R. and Stoltz, G.},
  Booktitle                = {{Proceedings of the 24th Conference On Learning Theory}},
  Year                     = {2011}
}

@Article{Mairal10OnlineNMF,
  Title                    = {{Online Learning for Matrix Factorization and Sparse Coding}},
  Author                   = {Mairal, J. and Bach, F. and Ponce, J. and Sapiro, G.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {19--60},
  Volume                   = {11},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{MannorTsi04,
  Title                    = {{The Sample Complexity of Exploration in the Multi-Armed Bandit Problem}},
  Author                   = {Mannor, S. and Tsitsiklis, J.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2004},
  Pages                    = {623--648},

  Abstract                 = {Setting: Fixed Confidence with epsilon>0, find the best arm (non asymptotic) lower bounds for Bernoulli rewrads: - a worst case LB scaling in epsilon - a LB scaling in epsilon and gaps but for parameter smaller than 1/2 (that involves some abstract parameter p -> not a sum over all arms) Thm 5 - a more complicated LB for 'general' parameter Thm 8 - a 'worse-case' Bayesian bound (there exists a prior) - a worst-case Lai and Robbins version (based on a Bayesian LB) in the regret setting - some stuff when the distributions are known},
  Owner                    = {kaufmann},
  Timestamp                = {2013.03.25}
}

@Article{MaronMoore:97,
  Title                    = {{The Racing algorithm: Model selection for Lazy learners}},
  Author                   = {Maron, O. and Moore, A.},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {1997},
  Pages                    = {113--131},
  Volume                   = {11(1-5)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.30}
}

@Book{massart2007,
  Title                    = {{Concentration inequalities and model selection}},
  Author                   = {Massart, P.},
  Publisher                = {Springer},
  Year                     = {2007},

  Address                  = {Berlin},
  Note                     = {Lectures from the 33rd Summer School on Probability Theory held in Saint-Flour, July 6--23, 2003},
  Series                   = {{Lecture Notes in Mathematics}},
  Volume                   = {1896},

  Pages                    = {xiv+337}
}

@Article{May:al12OBS,
  Title                    = {{Optimistic {B}ayesian sampling in contextual bandit problems}},
  Author                   = {May, B. and Korda, N. and A., Lee and D., Leslie},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2012},
  Pages                    = {2069--2106},
  Volume                   = {13},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@InProceedings{MellorShapiro13TSwitch,
  Title                    = {{Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection}},
  Author                   = {Mellor, J. and Shapiro, J.},
  Booktitle                = {{Proceeding of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{Mnih:Bernstein08,
  Title                    = {{Empirical {B}ernstein stopping}},
  Author                   = {Mnih, V. and Szepesv{\'a}ri, C. and Audibert, J-Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.08}
}

@InProceedings{MockusEI77,
  Title                    = {{On Bayesian methods for seeking the extremum and their application}},
  Author                   = {Mockus, Jonas},
  Booktitle                = {{Inf. Process. 77, Proc. IFIP Congr., Toronto 1977}},
  Year                     = {1977},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@Book{SurveyRemiMCTS,
  Title                    = {From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization and planning.},
  Author                   = {Munos, R.},
  Publisher                = {Foundations and Trends in Machine Learning},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {7},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@Article{Javidi13,
  Title                    = {{Active sequential hypothesis testing}},
  Author                   = {Naghshvar, M. and Javidi, T.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {2703--2738},
  Volume                   = {41(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Book{Neveu72,
  Title                    = {{Martingales {\`a} temps discret}},
  Author                   = {Neveu, Jacques},
  Publisher                = {Masson},
  Year                     = {1972},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.19}
}

@Article{NinoMora11Finite,
  Title                    = {{Computing a Classic Index for Finite-Horizon Bandits}},
  Author                   = {Nino-Mora, J.},
  Journal                  = {INFORMS Journal of Computing},
  Year                     = {2011},
  Pages                    = {254--267},
  Volume                   = {23(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@Article{Nino-Mora07,
  Title                    = {A (2/3)n3 Fast-Pivoting Algorithm for the Gittins Index and Optimal Stopping of a Markov Chain.},
  Author                   = {Niño-Mora, José},
  Journal                  = {INFORMS Journal on Computing},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {596-606},
  Volume                   = {19}
}

@Article{OQuigleyPF90CRM,
  Title                    = {Continual reassessment method: A practical design for Phase I clinical trials in cancer},
  Author                   = {O'Quigley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Number                   = {46},
  Pages                    = {33-48},

  Owner                    = {emilie},
  Timestamp                = {2016.11.02}
}

@Article{OQuingley90CRM,
  Title                    = {Continual Reassessment Method: A Practical Design for Phase {I} Clinical Trials in Cancer},
  Author                   = {O'Quingley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {33-48},
  Volume                   = {46},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@InProceedings{RussoVanRoy13RL,
  Title                    = {{(More) Efficient Reinforcement Learning Via Posterior Sampling}},
  Author                   = {Osband, I. and {Van Roy}, B. and Russo, D.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@Article{Paulson:94,
  Title                    = {{Sequential procedures for selecting the best one of k {K}oopman-{D}armois populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Sequential Analysis: Design Methods and Applications},
  Year                     = {1994},
  Pages                    = {207--220},
  Volume                   = {13},

  Abstract                 = {to pay, not found},
  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@Article{Paulson:64,
  Title                    = {{A sequential procedure for selecting the population with the largest mean from k normal populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1964},
  Pages                    = {174--180},
  Volume                   = {35},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@InProceedings{Pavlidis:al08IE,
  Title                    = {{Simulation studies of multi-armed bandits with covariates}},
  Author                   = {Pavlidis, N.G and Tasoulis, D.K. and Hand, D.J.},
  Booktitle                = {{10th Proceedings of the International Conference on Computer Modeling}},
  Year                     = {2008},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.04.16}
}

@Article{PenaSelf04,
  Title                    = {{Self-normalized Processes : Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {de la Pena, V.H. and Klass, M.J. and Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{PerchetRigollet13Covariates,
  Title                    = {The multi-armed bandit with covariates},
  Author                   = {Perchet, Vianney and Rigollet, Philippe},
  Journal                  = {The Annals of Statistics},
  Year                     = {2013},

  Owner                    = {emilie},
  Timestamp                = {2016.04.25}
}

@InProceedings{Perchet15Batched,
  Title                    = {Batched Bandit Problems},
  Author                   = {Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Eric},
  Booktitle                = {Proceedings of the 28th Conference On Learning Theory},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.04.25}
}

@Conference{Preux14Opt,
  Title                    = {{Bandits attack function optimization}},
  Author                   = {Preux, P. and Munos, R. and Valko, M.},
  Booktitle                = {{IEEE Congress on Evolutionary Computation}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Book{Puterman94MDP,
  Title                    = {{Markov Decision Processes. Discrete Stochastic. Dynamic Programming.}},
  Author                   = {Puterman, M.L.},
  Publisher                = {Wiley},
  Year                     = {1994},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@PhdThesis{TheseMKR14,
  Title                    = {Designs adaptatifs de recherche de dose en encologie dans le cadre de combinaisons de molécules et de molécules ciblées},
  Author                   = {Riviere, M-K.},
  School                   = {Université Paris-Diderot},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@Article{MKR16,
  Title                    = {Phase I/II Dose-Finding Design for Molecularly Targeted Agent: Plateau Determination using Adaptive Randomization},
  Author                   = {Rivière, M-K. and Jourdan, J-H. and Dubois F. and Zohar S.},
  Journal                  = {Statistical Methods in Medical Research},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.11.03}
}

@Article{Robbins70LIL,
  Title                    = {{Statistical Methods Related to the law of the iterated logarithm}},
  Author                   = {Robbins, H.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1970},
  Pages                    = {1397--1409},
  Volume                   = {41(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.01.21}
}

@Article{Robbins52Freq,
  Title                    = {{Some aspects of the sequential design of experiments}},
  Author                   = {Robbins, H.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1952},
  Pages                    = {527--535},
  Volume                   = {58(5)},

  Abstract                 = {First statement of the frequentist MAB Hannan consistent policies Looks for minmax rules epsilon greedy mentionned},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{RusTsi10,
  Title                    = {{Linearly Parameterized Bandits}},
  Author                   = {Rusmevichientong, P. and Tsitsiklis, J.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {2010},
  Pages                    = {395--411},
  Volume                   = {35(2)},

  Abstract                 = {stochastic linear bandit (regret and bayesian risk) -> no dual case (a priori) Lower bound on the regret for actions on the unit sphere (for regret and bayes risk) in the stochastic setting of O(d\sqrt(n)) PEGE algorithm (separate exploration and exploitation) matches the lower bound but is efficient only on (at least) compact and strongly convex sets of actions UE algorithm (action set included in some L2 bowl, subgaussian assumption on the noise) - regret bound (O(d\sqrt(n)\log^3(n))) in expactation but based on hp results - regret bound in the finite case where Delta is defined scaling in the gaps},
  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Russo16,
  Title                    = {Simple Bayesian algorithms for Best Arm Identification},
  Author                   = {Russo, D.},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@Article{RussoVanRoy13,
  Title                    = {{Learning to optimize via posterior sampling}},
  Author                   = {Russo, D. and {Van Roy}, B.},
  Journal                  = {Mathematics of Operations Research (to appear)},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@InProceedings{RussoVanRoy14IDS,
  Title                    = {Learning to optimize via information direct sampling},
  Author                   = {Russo, D. and Van Roy, B.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@InProceedings{SalomonAudibert:11Dev,
  Title                    = {{Deviations of stochastic bandit regret}},
  Author                   = {Salomon, A. and Audibert, J-Y.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Abstract                 = {PB : do Rn>Clog(n) have small probability answer : not so small for UCB, better when the horizon is known (negative result for anytime policy) UCB-H is better then UCB in terms of hp result (possible) PAC-UCB : fix our exploration rate building a sequence corresponding to our level of confidence},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@InProceedings{Sani:al12,
  Title                    = {{Risk-aversion in multi-armed bandits}},
  Author                   = {Sani, A. and Lazaric, A. and Munos, R.},
  Booktitle                = {{NIPS}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.07.18}
}

@Article{AmandineSTMALA,
  Title                    = {{A shrinkage-thresholding Metropolis adjusted Langevin algorithm for Bayesian variable selection}},
  Author                   = {Schreck, A. and Fort, G. and {Le Corff}, S. and Moulines, E.},
  Journal                  = {arXiv:1312.5658},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.06.23}
}

@Article{Scott10,
  Title                    = {{A modern Bayesian look at the multi-armed bandit}},
  Author                   = {Scott, S.L.},
  Journal                  = {Applied Stochastic Models in Business and Industry},
  Year                     = {2010},
  Pages                    = {639--658},
  Volume                   = {26},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@InProceedings{Shamir13Complexity,
  Title                    = {{On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization}},
  Author                   = {Shamir, O.},
  Booktitle                = {{Conference On Learning Theory}},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@Article{ShenOQ98ConsCRM,
  Title                    = {Consistency of continual reassessment method under model misspecification},
  Author                   = {Shen, L. and O'Quigley, J.},
  Journal                  = {Biometrika},
  Year                     = {1996},
  Number                   = {2},
  Pages                    = {395-405},
  Volume                   = {83},

  Owner                    = {emilie},
  Timestamp                = {2016.11.08}
}

@Book{Siegmund:SeqAn,
  Title                    = {{Sequential Analysis}},
  Author                   = {Siegmund, D.},
  Publisher                = {Springer-Verlag},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.30}
}

@Book{PDMIA08,
  Title                    = {{Processus Decisionnels de Markov et Intelligence artificielle}},
  Author                   = {Sigaud, O. and Buffet, O.},
  Publisher                = {Herm{\`e}s},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.31}
}

@Article{deep.go,
  Title                    = {Mastering the game of Go with deep neural networks and tree search },
  Author                   = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  Journal                  = {Nature},
  Year                     = {2016},
  Pages                    = {484--489},
  Volume                   = {529}
}

@InProceedings{Snoek14BOpt,
  Title                    = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
  Author                   = {Snoek, J. and Lrochelle, H. and Adams, R.P.},
  Booktitle                = {{Advances on Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Soare14BAILin,
  Title                    = {{Best Arm Identification in Linear Bandit}},
  Author                   = {Soare, M. and Lazaric, A. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{GPUCB:Journal,
  Title                    = {{Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Journal                  = {IEEE Transactions on Information Theory},
  Year                     = {2012},
  Pages                    = {3250--3265},
  Volume                   = {58(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@InProceedings{SrinivasGPUCB,
  Title                    = {{Gaussian Process Optimization in the Bandit Setting : No Regret and Experimental Design}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Booktitle                = {{Proceedings of the International Conference on Machine Learning}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Strens00TSRL,
  Title                    = {{A Bayesian Framework for Reinforcement Learning}},
  Author                   = {Strens, Malcom},
  Booktitle                = {{ICML}},
  Year                     = {2000},

  Abstract                 = {Thompson in RL},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.10}
}

@Book{SuttonBarto98,
  Title                    = {Reinforcement Learning: an Introduction},
  Author                   = {Sutton, R. and Barto, A.},
  Publisher                = {MIT press},
  Year                     = {1998},

  Owner                    = {emilie},
  Timestamp                = {2016.11.07}
}

@InProceedings{STOP14,
  Title                    = {Optimistic Planning in Markov Decision Processes using a generative model},
  Author                   = {Szorenyi, B. and Kedenburg, G. and Munos, R.},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{Thompson35,
  Title                    = {{On the theory of apportionment}},
  Author                   = {Thompson, W.},
  Journal                  = {American Journal of Mathematics},
  Year                     = {1935},
  Pages                    = {450--456},
  Volume                   = {57},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@Article{Rajesh15Oddball,
  Title                    = {Learning to detect an oddball target},
  Author                   = {N.K. Vaidhyan and R. Sundaresan},
  Journal                  = {arXiv:1508.05572},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.17}
}

@InProceedings{valko2013stochastic,
  Title                    = {{Stochastic simultaneous optimistic optimization}},
  Author                   = {Valko, Michal and Carpentier, Alexandra and Munos, R{\'{e}}mi},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2013},

  Abstract                 = {We study the problem of global maximization of a function f given a finite number of evaluations perturbed by noise. We consider a very weak assumption on the function, namely that it is locally smooth (in some precise sense) with respect to some semi-metric, around one of its global maxima. Compared to previous works on bandits in general spaces (Kleinberg et al., 2008; Bubeck et al., 2011a) our algorithm does not require the knowledge of this semi-metric. Our algorithm, StoSOO, follows an optimistic strategy to iteratively construct upper confidence bounds over the hierarchical partitions of the function domain to decide which point to sample next. A finite-time analysis of StoSOO shows that it performs almost as well as the best specifically-tuned algorithms even though the local smoothness of the function is not known.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Valko:al13KernelUCB,
  Title                    = {{Finite-time analysis of kernelized contextual bandits}},
  Author                   = {Valko, M. and Korda, N. and Munos, R. and Cristinini, N.},
  Booktitle                = {{29th Conference on Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Book{VdV:Asymptotic98,
  Title                    = {{Asymptotic Statistics}},
  Author                   = {{Van der Vaart}, A.},
  Publisher                = {Cambridge University Press},
  Year                     = {1998},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}


@InProceedings{aziz18alt,
  title = 	 {Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence},
  author = 	 {Maryam Aziz and Jesse Anderton and Emilie Kaufmann and Javed Aslam},
  booktitle = 	 {Proceedings of Algorithmic Learning Theory},
  pages = 	 {3--24},
  year = 	 {2018},
  editor = 	 {Firdaus Janoos and Mehryar Mohri and Karthik Sridharan},
  volume = 	 {83},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {07--09 Apr},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v83/aziz18a/aziz18a.pdf},
  url = 	 {http://proceedings.mlr.press/v83/aziz18a.html},
  abstract = 	 {We consider the problem of near-optimal arm identification in the fixed confidence setting of the infinitely armed bandit problem when nothing is known about the arm reservoir distribution. We (1) introduce a PAC-like framework within which to derive and cast results; (2) derive a sample complexity lower bound for near-optimal arm identification; (3) propose an algorithm that identifies a nearly-optimal arm with high probability and derive an upper bound on its sample complexity which is within a log factor of our lower bound; and (4) discuss whether our $\log^2 \frac{1}{δ}$ dependence is inescapable for “two-phase” (select arms first, identify the best later) algorithms in the infinite setting. This work permits the application of bandit models to a broader class of problems where fewer assumptions hold.}
}

@article{aziz19dose,
    title = {On Multi-Armed Bandit Designs for Phase {I} Clinical Trials},
    author = {Maryam Aziz and Emilie Kaufmann and Marie-Karelle Riviere},
    year = {2019}
}

@book{fashionhist,
    title = {Renaissance Clothing and the Materials of Memory},
    author = {Ann Rosalind Jones, Peter Stallybrass},
    journal = {Cambridge University Press},
    year = {2000}
}



@InProceedings{aziz19alt,
  title = 	 {Pure-exploration for Infinite-Armed Bandits with General Arm Reservoirs},
  author = 	 {Maryam Aziz and Kevin Jamieson and Javed Aslam},
  year = 	 {2019}
}

@article{aziz19dtree,
  author    = {Maryam Aziz and
               Jesse Anderton and
               Javed A. Aslam},
  title     = {Adaptively Pruning Features for Boosted Decision Trees},
  journal   = {CoRR},
  volume    = {abs/1805.07592},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.07592},
  archivePrefix = {arXiv},
  eprint    = {1805.07592},
  timestamp = {Mon, 13 Aug 2018 16:46:15 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-07592},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Appel:2013:QBD:3042817.3043003,
 author = {Appel, Ron and Fuchs, Thomas and Doll\'{a}r, Piotr and Perona, Pietro},
 title = {Quickly Boosting Decision Trees: Pruning Underachieving Features Early},
 booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
 series = {ICML'13},
 year = {2013},
 location = {Atlanta, GA, USA},
 pages = {III-594--III-602},
 url = {http://dl.acm.org/citation.cfm?id=3042817.3043003},
 acmid = {3043003},
 publisher = {JMLR.org},
}

@article{DBLP:journals/corr/ChenG16,
  author    = {Tianqi Chen and
               Carlos Guestrin},
  title     = {XGBoost: {A} Scalable Tree Boosting System},
  journal   = {CoRR},
  volume    = {abs/1603.02754},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.02754},
  archivePrefix = {arXiv},
  eprint    = {1603.02754},
  timestamp = {Mon, 13 Aug 2018 16:47:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChenG16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@online{pest,
  author = {Wikipedia},
  title = {PEST Analysis},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/PEST_analysis},
}

@online{fforecasting,
  author = {Wikipedia},
  title = {Fashion Forecasting},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/Fashion_forecasting}


@online{moodboard,
  author = {Wikipedia},
  title = {Mood Board},
  year = 2018,
  url = {https://en.wikipedia.org/wiki/Mood_board}

  
@article{Kaminskas:2016:DSN:3028254.2926720,
 author = {Kaminskas, Marius and Bridge, Derek},
 title = {Diversity, Serendipity, Novelty, and Coverage: A Survey and Empirical Analysis of Beyond-Accuracy Objectives in Recommender Systems},
 journal = {ACM Trans. Interact. Intell. Syst.},
 issue_date = {March 2017},
 volume = {7},
 number = {1},
 month = dec,
 year = {2016},
 issn = {2160-6455},
 pages = {2:1--2:42},
 articleno = {2},
 numpages = {42},
 url = {http://doi.acm.org/10.1145/2926720},
 doi = {10.1145/2926720},
 acmid = {2926720},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Evaluation metrics, beyond accuracy, coverage, diversity, novelty, serendipity},
} 

@article{li2017hyperband,
  title={Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.},
  author={Li, Lisha and Jamieson, Kevin G and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={185--1},
  year={2017}
}

@article{Bellet2013ASO,
  title={A Survey on Metric Learning for Feature Vectors and Structured Data},
  author={Aur{\'e}lien Bellet and Amaury Habrard and Marc Sebban},
  journal={CoRR},
  year={2013},
  volume={abs/1306.6709}
}

@inproceedings{Yang2007EvaluatingBR,
  title={Evaluating bag-of-visual-words representations in scene classification},
  author={Jun Yang and Yu-Gang Jiang and Alexander G. Hauptmann and Chong-Wah Ngo},
  booktitle={Multimedia Information Retrieval},
  year={2007}
}

@inproceedings{Wu:2018:LCB:3209978.3210051,
 author = {Wu, Qingyun and Iyer, Naveen and Wang, Hongning},
 title = {Learning Contextual Bandits in a Non-stationary Environment},
 booktitle = {The 41st International ACM SIGIR Conference on Research \&\#38; Development in Information Retrieval},
 series = {SIGIR '18},
 year = {2018},
 isbn = {978-1-4503-5657-2},
 location = {Ann Arbor, MI, USA},
 pages = {495--504},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3209978.3210051},
 doi = {10.1145/3209978.3210051},
 acmid = {3210051},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {non-stationary bandit, recommender systems, regret analysis},
} 

@article{ren2018exploring,
  title={Exploring $k$ out of Top $\rho$ Fraction of Arms in Stochastic Bandits},
  author={Ren, Wenbo and Liu, Jia and Shroff, Ness},
  journal={arXiv preprint arXiv:1810.11857},
  year={2018}
}

@online{new_yorker_contest,
  author = {TNYM, The New Yorker Magazine},
  title = {Data from the New Yorker Caption Contest},
  year = 2018,
  url = {https://github.com/nextml/caption-contest-data},
  urldate = {2018-09-27}
}



@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{Chan2018Infinite,
  title={Infinite Arms Bandit: Optimality via Confidence Bounds},
  author={Hock Peng Chan and Shouri Hu},
  journal={CoRR},
  year={2018},
  volume={abs/1805.11793}
}

@inproceedings{Jamieson2014lilU,
  title={lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits},
  author={Kevin G. Jamieson and Matthew Malloy and Robert D. Nowak and S{\'e}bastien Bubeck},
  booktitle={COLT},
  year={2014}
}

@incollection{NIPS2015_5868,
title = {NEXT: A System for Real-World Development, Evaluation, and Application of Active Learning},
author = {Jamieson, Kevin G and Jain, Lalit and Fernandez, Chris and Glattard, Nicholas J. and Nowak, Rob},
booktitle = {Advances in Neural Information Processing Systems 28},
pages = {2656--2664},
year = {2015},
}

@inproceedings{Jamieson2016NonstochasticBA,
  title={Non-stochastic Best Arm Identification and Hyperparameter Optimization},
  author={Kevin G. Jamieson and Ameet Talwalkar},
  booktitle={AISTATS},
  year={2016}
}

@inproceedings{li2017infinitely,
  title={Infinitely Many-Armed Bandits with Budget Constraints.},
  author={Li, Haifang and Xia, Yingce},
  booktitle={AAAI},
  pages={2182--2188},
  year={2017}
}
   
@incollection{wang2008,
title = {Algorithms for Infinitely Many-Armed Bandits},
author = {Yizao Wang and Jean-yves Audibert and R\'{e}mi Munos},
booktitle = {Advances in Neural Information Processing Systems 21},
pages = {1729--1736},
year = {2009},
}

@inproceedings{david2014infinitely,
  title={Infinitely many-armed bandits with unknown value distribution},
  author={David, Yahel and Shimkin, Nahum},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={307--322},
  year={2014},
  organization={Springer}
}

@inproceedings{david2015refined,
  title={Refined algorithms for infinitely many-armed bandits with deterministic rewards},
  author={David, Yahel and Shimkin, Nahum},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={464--479},
  year={2015},
  organization={Springer}
}

@inproceedings{chaudhuriquantile,
  title={Quantile-Regret Minimisation in Infinitely Many-Armed Bandits},
  author={Chaudhuri, Arghya Roy and Kalyanakrishnan, Shivaram}
  booktitle={UAI},
  year={2018}
}

@inproceedings{aziz2018pure,
  title={Pure Exploration in Infinitely-Armed Bandit Models with Fixed-Confidence},
  author={Aziz, Maryam and Anderton, Jesse and Kaufmann, Emilie
   and Aslam, Javed},
  booktitle={ALT 2018-Algorithmic Learning Theory},
  year={2018}
}

@article{kaufmann2016complexity,
  title={On the complexity of best-arm identification in multi-armed bandit models},
  author={Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1--42},
  year={2016},
  publisher={JMLR. org}
}

@article{chen2017nearly,
  title={Nearly instance optimal sample complexity bounds for top-k arm selection},
  author={Chen, Lijie and Li, Jian and Qiao, Mingda},
  journal={arXiv preprint arXiv:1702.03605},
  year={2017}
}

@inproceedings{chaudhuri2017pac,
  title={PAC Identification of a Bandit Arm Relative to a Reward Quantile.},
  author={Chaudhuri, Arghya Roy and Kalyanakrishnan, Shivaram},
  booktitle={AAAI},
  pages={1777--1783},
  year={2017}
}

@inproceedings{teytaud2007anytime,
  title={Anytime many-armed bandits},
  author={Teytaud, Olivier and Gelly, Sylvain and Sebag, Michele},
  booktitle={CAP07},
  year={2007}
}

@inproceedings{malloy2012quickest,
  title={Quickest search for a rare distribution},
  author={Malloy, Matthew L and Tang, Gongguo and Nowak, Robert D},
  booktitle={Information Sciences and Systems (CISS), 2012 46th Annual Conference on},
  pages={1--6},
  year={2012},
  organization={IEEE}
}

@inproceedings{chandrasekaran2014finding,
  title={Finding a most biased coin with fewest flips},
  author={Chandrasekaran, Karthekeyan and Karp, Richard},
  booktitle={Conference on Learning Theory},
  pages={394--407},
  year={2014}
}

@inproceedings{jamieson2016power,
  title={The power of adaptivity in identifying statistical alternatives},
  author={Jamieson, Kevin G and Haas, Daniel and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={775--783},
  year={2016}
}

@inproceedings{bonald2013two,
  title={Two-target algorithms for infinite-armed bandits with Bernoulli rewards},
  author={Bonald, Thomas and Proutiere, Alexandre},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2184--2192},
  year={2013}
}

@INPROCEEDINGS{Schapire90thestrength,
    author = {Robert E. Schapire},
    title = {The Strength of Weak Learnability},
    booktitle = {Machine Learning},
    year = {1990}
}

@incollection{NIPS2015_6027,
title = {On Top-k Selection in Multi-Armed Bandits and Hidden Bipartite Graphs},
author = {Cao, Wei and Li, Jian and Tao, Yufei and Li, Zhize},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N.D. Lawrence and D.D. Lee and M. Sugiyama and R. Garnett and R. Garnett},
pages = {1036--1044},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@inproceedings{DBLP:conf/nips/ChenLKLC14,
  author    = {Shouyuan Chen and
               Tian Lin and
               Irwin King and
               Michael R. Lyu and
               Wei Chen},
  title     = {Combinatorial Pure Exploration of Multi-Armed Bandits},
  booktitle = {Advances in Neural Information Processing Systems 27: Annual Conference
               on Neural Information Processing Systems 2014, December 8-13 2014,
               Montreal, Quebec, Canada},
  pages     = {379--387},
  year      = {2014},
  timestamp = {Wed, 10 Dec 2014 21:34:12 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanTAS12,
  author    = {Shivaram Kalyanakrishnan and
               Ambuj Tewari and
               Peter Auer and
               Peter Stone},
  title     = {{PAC} Subset Selection in Stochastic Multi-armed Bandits},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning,
               {ICML} 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012},
  year      = {2012},
  timestamp = {Fri, 25 Jan 2013 09:27:52 +0100},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{2013arXiv1302.1611B,
   author = {{Bubeck}, S. and {Perchet}, V. and {Rigollet}, P.},
    title = "{Bounded regret in stochastic multi-armed bandits}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1302.1611},
 primaryClass = "math.ST",
 keywords = {Mathematics - Statistics Theory, Computer Science - Learning, Statistics - Machine Learning, 62L05},
     year = 2013,
    month = feb,
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Even-Dar:2006:AES:1248547.1248586,
 author = {Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
 title = {Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2006},
 volume = {7},
 month = dec,
 year = {2006},
 issn = {1532-4435},
 pages = {1079--1105},
 numpages = {27},
 acmid = {1248586},
 publisher = {JMLR.org},
}

@inproceedings{DBLP:conf/icml/KalyanakrishnanS10,
  author    = {Shivaram Kalyanakrishnan and
               Peter Stone},
  title     = {Efficient Selection of Multiple Bandit Arms: Theory and Practice},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
               (ICML-10), June 21-24, 2010, Haifa, Israel},
  pages     = {511--518},
  year      = {2010},
  timestamp = {Fri, 12 Jun 2015 19:15:11 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{10.2307/2332286,
 ISSN = {00063444},
 author = {William R. Thompson},
 journal = {Biometrika},
 number = {3/4},
 pages = {285-294},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples},
 volume = {25},
 year = {1933}
}

@article{Lai19854,
title = "Asymptotically efficient adaptive allocation rules ",
journal = "Advances in Applied Mathematics ",
volume = "6",
number = "1",
pages = "4 - 22",
year = "1985",
note = "",
issn = "0196-8858",
doi = "http://dx.doi.org/10.1016/0196-8858(85)90002-8",
author = "T.L Lai and Herbert Robbins"
}

@article{Burnetas1996122,
title = "Optimal Adaptive Policies for Sequential Allocation Problems ",
journal = "Advances in Applied Mathematics ",
volume = "17",
number = "2",
pages = "122 - 142",
year = "1996",
note = "",
issn = "0196-8858",
doi = "http://dx.doi.org/10.1006/aama.1996.0007",
author = "Apostolos N. Burnetas and Michael N. Katehakis"
}

@book{WaldsLemma,
title  = {Sequential Analysis},
author = {David Siegmund},
year = {1985},
}

@book{Cover:2006:EIT:1146355,
 author = {Cover, Thomas M. and Thomas, Joy A.},
 title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
 year = {2006},
 isbn = {0471241954},
 publisher = {Wiley-Interscience},
} 

@article{DBLP:journals/corr/CarpentierV15,
  author    = {Alexandra Carpentier and
               Michal Valko},
  title     = {Simple regret for infinitely many armed bandits},
  journal   = {CoRR},
  volume    = {abs/1505.04627},
  year      = {2015},
  timestamp = {Mon, 01 Jun 2015 14:13:54 +0200},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{Escudero:2001:ULW:2387364.2387381,
 author = {Escudero, G. and M\`{a}rquez, L. and Rigau, G.},
 title = {Using LazyBoosting for Word Sense Disambiguation},
 booktitle = {The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems},
 series = {SENSEVAL '01},
 year = {2001},
 location = {Toulouse, France},
 pages = {71--74},
 numpages = {4},
 acmid = {2387381},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{csiszar1984,
author = "Csiszar, Imre",
doi = "10.1214/aop/1176993227",
fjournal = "The Annals of Probability",
journal = "Ann. Probab.",
month = "08",
number = "3",
pages = "768--793",
publisher = "The Institute of Mathematical Statistics",
title = "Sanov Property, Generalized $I$-Projection and a Conditional Limit Theorem",
volume = "12",
year = "1984"
}



@inproceedings{journals/jmlr/GarivierC11,
  added-at = {2013-11-25T00:00:00.000+0100},
  author = {Garivier, Aurélien and Cappé, Olivier},
  biburl = {http://www.bibsonomy.org/bibtex/2eaa70f360a064c34e95c79775fd5aaa8/dblp},
  booktitle = {COLT},
  crossref = {conf/colt/2011},
  editor = {Kakade, Sham M. and von Luxburg, Ulrike},
  ee = {http://www.jmlr.org/proceedings/papers/v19/garivier11a/garivier11a.pdf},
  interhash = {2f239ff7ecaa45d8963b3db2978c960e},
  intrahash = {eaa70f360a064c34e95c79775fd5aaa8},
  keywords = {dblp},
  pages = {359-376},
  publisher = {JMLR.org},
  series = {JMLR Proceedings},
  timestamp = {2015-06-19T12:47:52.000+0200},
  title = {The KL-UCB Algorithm for Bounded Stochastic Bandits and Beyond.},
  url = {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp19.html#GarivierC11},
  volume = 19,
  year = 2011
}

@article{Lampret:2015:ADI:2828645.2828929,
 author = {Lampret, Vito},
 title = {Accurate Double Inequalities for Generalized Harmonic Numbers},
 journal = {Appl. Math. Comput.},
 issue_date = {August 2015},
 volume = {265},
 number = {C},
 month = aug,
 year = {2015},
 issn = {0096-3003},
 pages = {557--567},
 numpages = {11},
 url = {http://dx.doi.org/10.1016/j.amc.2015.04.128},
 doi = {10.1016/j.amc.2015.04.128},
 acmid = {2828929},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {11Y60, 33E20, 33F05, 40A25, 41A60, 65B10, 65B15, Approximation, Estimate, Euler-Maclaurin summation, Generalized harmonic number, Zeta-generalized-Euler-constant function, p-series},
}

@InProceedings{Kleinberg08Infinite,
  Title                    = {Multi-armed bandit in metric spaces},
  Author                   = {Kleinberg, R. and Slivkins, A. and Upfal, E.},
  Booktitle                = {Proceedings of the 40th ACM Symposium on Theory of Computing},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2017.02.20}
}

@Article{Bubeck11Xarmed,
  Title                    = {X-armed bandits},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G. and Szepesv\'{a}ri, C.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {1587-1627},
  Volume                   = {12},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{grill2015black-box,
  Title                    = {{Black-box optimization of noisy functions with unknown smoothness}},
  Author                   = {Grill, Jean-Bastien and Valko, Michal and Munos, R{\'{e}}mi},
  Booktitle                = {Advances on Neural Information Processing Systems (NIPS)},
  Year                     = {2015},

  Abstract                 = {We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO's performance, which shows that its error after n evaluations is at most a factor of sqrt(ln n) away from the error of the best known optimization algorithms using the knowledge of the smoothness.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@inproceedings{simchowitz2017simulator,
  title={The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime},
  author={Simchowitz, Max and Jamieson, Kevin and Recht, Benjamin},
  booktitle={Conference on Learning Theory},
  pages={1794--1834},
  year={2017}
}

@InProceedings{kl-lucbCOLT13,
  Title                    = {{Information complexity in bandit subset selection}},
  Author                   = {Kaufmann, E. and Kalyanakrishnan, S.},
  Booktitle                = {{Proceeding of the 26th Conference On Learning Theory.}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@Article{LaiRobbins85bandits,
  Title                    = {{Asymptotically efficient adaptive allocation rules}},
  Author                   = {Lai, T.L. and Robbins, H.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Date-modified            = {2010-02-02 03:14:31 -0700},
  Publisher                = {Elsevier}
}

@Article{BurnKat96,
  Title                    = {{Optimal adaptive policies for sequential allocation problems}},
  Author                   = {Burnetas, A.N and Katehakis, M.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1996},
  Pages                    = {122--142},
  Volume                   = {17(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Combes14Lip,
  Title                    = {{Lipschitz Bandits: Regret lower bounds and optimal algorithms}},
  Author                   = {Magureanu, S. and Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {{Proceedings on the 27th Conference On Learning Theory}},
  Year                     = {2014}
}

@Article{EvenDaral06,
  Title                    = {{Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems}},
  Author                   = {Even-Dar, E. and Mannor, S. and Mansour, Y.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1079--1105},
  Volume                   = {7},

  Abstract                 = {Pure exploration problem of finding the best arm in a PAC setting (with a level epsilon of tolerance) Several algorithms are proposed, with successive elimination sometimes},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@inproceedings{bubeck2009pure,
  title={Pure exploration in multi-armed bandits problems},
  author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles},
  booktitle={International conference on Algorithmic learning theory},
  pages={23--37},
  year={2009},
  organization={Springer}
}

@inproceedings{carpentier2016tight,
  title={Tight (lower) bounds for the fixed budget best arm identification bandit problem},
  author={Carpentier, Alexandra and Locatelli, Andrea},
  booktitle={Conference on Learning Theory},
  pages={590--604},
  year={2016}
}

@article{li2017hyperband,
  title={Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization.},
  author={Li, Lisha and Jamieson, Kevin G and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={185--1},
  year={2017}
}

@InProceedings{GK16,
  Title                    = {Optimal Best Arm Identification with Fixed Confidence},
  Author                   = {Garivier, Aur{\'e}lien and Kaufmann, Emilie},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016}
}

% This file was created with JabRef 2.10b2.
% Encoding: UTF-8

@BOOK{chevret06,
  title = {Statistical Methods for dose-Finding Experiments},
  publisher = {John Wiley and Sons Ltd.},
  year = {2006},
  author = {Chevret, S.},
  series = {Statistics in Practice},
  address = {Chichester}
}

@ARTICLE{faries94,
  author = {Faries, D. },
  title = {{{P}ractical modifications of the continual reassessment method for
	phase {I} cancer clinical trials}},
  journal = {J Biopharm Stat},
  year = {1994},
  volume = {4},
  pages = {147--164},
  number = {2},
  month = {Jul}
}

@ARTICLE{storer89,
  author = {Storer, B. E.},
  title = {Design and analysis of phase {I} clinical trials},
  journal = {Biometrics},
  year = {1989},
  volume = {45},
  pages = {925-37}
}

@ARTICLE{letourneau10,
  author = {Le Tourneau, C. and Dieras, V. and Tresca, P. and Cacheux, W. and
	Paoletti, X.},
  title = {{{C}urrent challenges for the early clinical development of anticancer
	drugs in the era of molecularly targeted agents}},
  journal = {Target Oncol},
  year = {2010},
  volume = {5},
  pages = {65--72},
  number = {1},
  month = {Mar}
}

@ARTICLE{letourneau12,
  author = {Le Tourneau, C. and Gan, H. K. and Razak, A. R. and Paoletti, X.},
  title = {{{E}fficiency of new dose escalation designs in dose-finding phase
	{I} trials of molecularly targeted agents}},
  journal = {PLoS ONE},
  year = {2012},
  volume = {7},
  pages = {e51039},
  number = {12}
}

@ARTICLE{letourneau11,
  author = {Le Tourneau, C. and Razak, A. R. and Gan, H. K. and Pop, S. and Dieras,
	V. and Tresca, P. and Paoletti, X.},
  title = {{{H}eterogeneity in the definition of dose-limiting toxicity in phase
	{I} cancer clinical trials of molecularly targeted agents: a review
	of the literature}},
  journal = {Eur. J. Cancer},
  year = {2011},
  volume = {47},
  pages = {1468--1475},
  number = {10},
  month = {Jul}
}

@article{Garivier17DF,
author = {Garivier, A. and M\'enard, P. and Rossi, L.},
title = {Thresholding Bandit for Dose-ranging: The Impact of Monotonicity},
journal = {arXiv:1711.04454},
year = {2017}}


@ARTICLE{Postel-Vinay09,
  author = {Postel-Vinay, S. and Arkenau, H. T. and Olmos, D. and Ang, J. and
	Barriuso, J. and Ashley, S. and Banerji, U. and De-Bono, J. and Judson,
	I. and Kaye, S.},
  title = {{{C}linical benefit in {P}hase-{I} trials of novel molecularly targeted
	agents: does dose matter?}},
  journal = {Br. J. Cancer},
  year = {2009},
  volume = {100},
  pages = {1373--1378},
  number = {9},
  month = {May}
}



@ARTICLE{CheungChappell02,
  author = {Cheung, Y.K. and Chappell, R.},
  title = {A simple technique to evaluate model sensitivity in the Continual
Reassessment Method},
  journal = {Biometrics},
  year = {2002},
  volume = {59},
  pages = {671--674}
}

@ARTICLE{ShenOQuigley96,
  author = {Shen, L. and O'Quigley, J.},
  title = {Consistency of the continual reassessment method under model mispecification},
  journal = {Biometrika},
  year = {1996},
  volume = {83},
  pages = {395--405}
}


@ARTICLE{hoering11,
  author = {Hoering, A. and LeBlanc, M. and Crowley, J. },
  title = {{{S}eamless phase {I}-{I}{I} trial design for assessing toxicity
	and efficacy for targeted agents}},
  journal = {Clin. Cancer Res.},
  year = {2011},
  volume = {17},
  pages = {640--646},
  number = {4},
  month = {Feb}
}

@article{MKR17,
author = {Marie-Karelle Riviere and Ying Yuan and Jacques-Henri Jourdan and Frédéric Dubois and Sarah Zohar},
title ={Phase I/II dose-finding design for molecularly targeted agent: Plateau determination using adaptive randomization},
journal = {Statistical Methods in Medical Research},
pages = {0962280216631763},
year = {2017},
doi = {10.1177/0962280216631763},
}

@InProceedings{YadLinear11,
  Title                    = {{Improved Algorithms for Linear Stochastic Bandits}},
  Author                   = {Abbasi-Yadkori, Y. and D.P{\'a}l and C.Szepesv{\'a}ri},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Abstract                 = {stochastic linear bandit, 'dual setting', action set that can vary in time, subgaussian assumption on the noise OFUL: regret bound slightly better than Rus-Tsi, interesting concentration arguments},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}



@Article{Agrawal:95,
  Title                    = {{Sample mean based index policies with O(log n) regret for the multi-armed bandit problem}},
  Author                   = {Agrawal, R.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {1054--1078},
  Volume                   = {27},

  Publisher                = {JSTOR}
}

@Article{Mozgunov17CT,
  Title                    = {{An information-theoretic approach for selecting arms in clinical trials}},
  Author                   = {Mozgunov, P. and Jaki, T.},
  Journal                  = {arXiv:1708.02426 },
  Year                     = {2017},
}

@Article{Agrawaletal89LBGene,
  Title                    = {{Asymptotically Efficient Adaptive Allocation Schemes for Controlled i.i.d. Processes: Finite Parameter Space}},
  Author                   = {Agrawal, R. and Teneketzis, D. and Anantharam, V.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1989},
  Pages                    = {258--267},
  Volume                   = {34(3)},

  Abstract                 = {A rapprocher de Graves et Lai pour la generalisation de la borne de Lai et Robbins, dans un cas plus simple (avec une preuve plus claire que l'on peut adapter !)},
  Owner                    = {kaufmann},
  Timestamp                = {2014.03.12}
}

@inproceedings{LiCLS10News,
  author    = {Li, L. and
               Chu, W. and
               Langford, J. and
               Schapire, R.},
  title     = {A contextual-bandit approach to personalized news article recommendation},
  booktitle = {Proceedings of the 19th International Conference on World Wide Web,
               {WWW} 2010},
  year      = {2010}
}

@article{Anandkumar11,
    title    =     {Distributed algorithms for learning and cognitive medium access with logarithmic regret},
    author   =     {A. Anandkumar and N. Michael and A. K. Tang and S. Agrawal},
    journal  =     {IEEE Journal on Selected Areas in Communications},
    volume   =     {29},
    number   =     {4},
    pages    =     {731--745},
    year     =     {2011}
}

@InProceedings{AGAISTAT13,
  Title                    = {{Further Optimal Regret Bounds for Thompson Sampling}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{AGContext13,
  Title                    = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}


@incollection{BanditBook18,
author = {Lattimore, Tor and Szepesvari, Csaba},
publisher = {Cambridge University Press},
title = {{Bandit Algorithms}},
url = {http://downloads.tor-lattimore.com/book.pdf},
year = {2018}
}

@InProceedings{AGCOLT12,
  Title                    = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{Alonal15GraphFeedback,
  Title                    = {Online Learning with Feedback Graph: Beyond Bandits},
  Author                   = {Alon, N. and Cesa-Bianchi, N. and Dekel, O. and Koren, T.},
  Booktitle                = {Conference On Learning Theory (COLT)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@Article{Anantharam87,
  Title                    = {Asymptotically Efficient Allocation Rules for the Multiarmed Bandit Problem with Multiple Plays-Part I: I.I.D. Rewards},
  Author                   = {Anantharam, V. and Varaya, P. and Walrand, J.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1987},
  Number                   = {11},
  Pages                    = {968-976},
  Volume                   = {32},

  Owner                    = {emilie},
  Timestamp                = {2016.03.29}
}

@InProceedings{CsabaTracking,
  Title                    = {Active Learning in Multi-Armed Bandits},
  Author                   = {Antos, A. and Grover, V. and Szepesv\'{a}ri, C.},
  Booktitle                = {Algorithmic Learning Theory},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{Asmuthal09BOSS,
  Title                    = {{A Bayesian sampling approach to exploration in reinforcement learning}},
  Author                   = {Asmuth, J. and Li, L. and Littman, M.L. and Nouri, A. and Wingate, D.},
  Booktitle                = {{Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@Article{Audibertal10MOSS,
  Title                    = {{Regret Bounds and Minimax Policies under Partial Monitoring}},
  Author                   = {Audibert, J-Y. and Bubeck, S.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Audibertal11,
  Title                    = {{Minimax Policies for Combinatorial Prediction Games}},
  Author                   = {Audibert, J-Y. and Bubeck, S. and Lugosi, G.},
  Booktitle                = {{Conference On Learning Theory (COLT)}},
  Year                     = {2011},

  Abstract                 = {adversarial linear bandit when D={0,1}^d Lower bound in the dual setting : 0.005 d\sqrt(n) Lower bound in the setting where the loss of the adversary is simply bounded by 1 : 0.01d^{3/2}\sqrt{n} EXP2 algorithm as a generalization of COMBAND},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}


@Article{Audibertal09UCBV,
  Title                    = {{Exploration-exploitation trade-off using variance estimates in multi-armed bandits}},
  Author                   = {Audibert, J-Y. and Munos, R. and Szepesv{\'a}ri, {Cs.}},
  Journal                  = {Theoretical Computer Science},
  Year                     = {2009},
  Number                   = {19},
  Volume                   = {410},

  File                     = {TCS08.pdf:http\://imagine.enpc.fr/publications/papers/TCS08.pdf:PDF}
}

@Article{Auer02,
  Title                    = {{Using Confidence bounds for Exploration Exploitation trade-offs}},
  Author                   = {Auer},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2002},
  Pages                    = {397--422},
  Volume                   = {3},

  Abstract                 = {- a variant of EXP3 for shifting bandit in the adversarial case [previous work of Auer on the adversarial bandit seems large] - LinRel algorithm for stochastic linear bandit (not under this name), states the Stochastic Linear Bandit Problem (?)},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.15}
}

@Article{Aueral02,
  Title                    = {{Finite-time analysis of the multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Fischer, P.},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {235--256},
  Volume                   = {47},

  Publisher                = {Springer}
}

@Article{Auer:al02EXP3,
  Title                    = {{The nonstochastic multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Freund, Y. and Schapire, R.},
  Journal                  = {SIAM Journal of Computing},
  Year                     = {2002},
  Pages                    = {48--77},
  Volume                   = {32(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Article{Balcan10Active,
  Title                    = {{The true sample complexity of active learning}},
  Author                   = {Balcan, M-F. and Hanneke, S. and {Wortman Voghan}, J.},
  Journal                  = {Machine Learning},
  Year                     = {2010},
  Pages                    = {111--139},
  Volume                   = {80}
}

@Article{Bechofer:54,
  Title                    = {{A single-sample multiple decision procedure for ranking means of normal populations with known variances}},
  Author                   = {Bechhofer, R.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1954},
  Pages                    = {16--39},
  Volume                   = {25},

  Abstract                 = {Static strategies for the gaussian case with known or unkown, similar or disimilar variances N=N\_1 + ... + N\_k samples. How to choose the N\_i (as small as possible) to achieve a given probability of error when the delta between the arms is known? (sufficient condition) Based on approximation of the probability of good ranking (a lower bound of the quantity is obtained in the least favorable 'slippage' configuration). The author provides a table that helps choosing N\_i in practise.},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@Book{Bechofer:al68,
  Title                    = {{Sequential identification and ranking procedures}},
  Author                   = {Bechhofer, Robert and Kiefer, Jack and Sobel, Milton},
  Publisher                = {The University of Chicago Press},
  Year                     = {1968},

  Abstract                 = {State the ranking and identification procedures with 'PCS1' probability conditions. No 'optimal' procedure, rather efficient procedures, based on fully uniform sampling: - for the identification problem: 'maximum a posteriori' with an uniform prior (possible to express in terms of likelihood) - for the ranking problem (for exponential families): use the same procedure, expressed in terms of gaps, and replace gaps by what they are in the Least Favorable (Slippage) configuration (heavily dependent on the delta parameter) Achieve the same garantee in terms of sample complexity as what can be done for a sequential multiple hypothesis testing based on K samples (and procedures for this purpose are hard to design!)},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@Article{Bellman:Bay56,
  Title                    = {{A problem in the sequential design of experiments}},
  Author                   = {Bellman, R.},
  Journal                  = {The indian journal of statistics},
  Year                     = {1956},
  Pages                    = {221--229},
  Volume                   = {16(3/4)},

  Abstract                 = {historical introduction general presentation of the bayesian bandit framework for two arms (discounted !) study the uncorelated case, 1/2 problem, in the discounted setting => discribe the stopping policy in terms of an index},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Bellman:54DP,
  Title                    = {{The theory of dynamic programming}},
  Author                   = {Bellman, R.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1954},
  Pages                    = {503--515},
  Volume                   = {60(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.28}
}

@Book{Berry:Fristedt85,
  Title                    = {{Bandit Problems. Sequential allocation of experiments}},
  Author                   = {Berry, D.A. and Fristedt, B.},
  Publisher                = {Chapman and Hall},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.21}
}

@Book{Bickel:Doksum,
  Title                    = {{Mathematical Statistics, Basic Ideas and Selected Topics}},
  Author                   = {Bickel, P. and Doksum, K.A.},
  Publisher                = {Prentice Hall},
  Year                     = {2001},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Book{Bishop06Laplace,
  Title                    = {{Pattern Recognition and Machine Learning}},
  Author                   = {Bishop, C.M.},
  Publisher                = {Springer-Verlag New York},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@InProceedings{OMS14,
  Title                    = {An analysis of optimistic, best-first search for minimax sequential decision making},
  Author                   = {Borsoniu, L. and Munos, R. and P{\'a}ll, E.},
  Booktitle                = {ADPRL14},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Book{Boucheronal13CI,
  Title                    = {{Concentration inequalities. A non asymptotic theory of independence.}},
  Author                   = {Boucheron, S., S. and Lugosi, G. and Massart, P},
  Publisher                = {Oxford University Press},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bradt:al56,
  Title                    = {{On sequential designs for maximizing the sum of n observations}},
  Author                   = {Bradt, R.N and Johnson, S.M. and Karlin, S.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1956},
  Pages                    = {1060--1074},
  Volume                   = {27(4)},

  Abstract                 = {contains the finite time Gittins indices ! bayesian finite-horizon framework - special case with a prior charging two values ('hypotheses' setting of Sonin) - product prior F(p)F(q) exactly solved for n=2 - solving the one-armed bandit with finite time exactly (approximation of Gittins indices) Link between the one-armed problem and the Gittins index : established by Gittins ! contient des relations entre indices finis},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Brezzi:Lai02,
  Title                    = {{Optimal learning and experimentation in bandit problems}},
  Author                   = {Brezzi, M. and Lai, T.},
  Journal                  = {Journal of Economics Dynamics and Control},
  Year                     = {2002},
  Pages                    = {87--108},
  Volume                   = {27},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Brezzi:LaiTech,
  Title                    = {{Incomplete learning fomr endogenous data in dynamic allocation}},
  Author                   = {Brezzi, M. and Lai, T.},
  Institution              = {Stanford University},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Brochu10Tuto,
  Title                    = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
  Author                   = {Brochu, E. and Cora, V.M. and {De Freitas}, N.},
  Institution              = {University of Bristish Columbia},
  Year                     = {2010},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@Article{SurveyMCTS12,
  Title                    = {A Survey of Monte Carlo Tree Search Methods},
  Author                   = {Browne, C. and Powley, E. and Whitehouse, D. and Lucas, S. and Cowling, P. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
  Journal                  = {IEEE Transactions on Computational Intelligence and AI in games,},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {1-49},
  Volume                   = {4},

  Owner                    = {emilie},
  Timestamp                = {2016.02.12}
}

@TechReport{Bubeck:LectOpt11,
  Title                    = {{Introduction to Online Optimization}},
  Author                   = {Bubeck, S.},
  Institution              = {Lecture Notes, Princeton University},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@PhdThesis{Bubeck:Thesis,
  Title                    = {{Jeux de bandits et fondation du clustering}},
  Author                   = {Bubeck, S.},
  School                   = {Universit{\'e} de Lille 1},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bubeck:Survey12,
  Title                    = {{Regret analysis of stochastic and nonstochastic multi-armed bandit problems}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N.},
  Journal                  = {Fondations and Trends in Machine Learning},
  Year                     = {2012},
  Pages                    = {1--122},
  Volume                   = {5(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.13}
}

@InProceedings{Bubeck:al12,
  Title                    = {{Towards Minimax Policies for Online Linear Opimization with Bandit Feedback}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N. and Kakade, S.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Abstract                 = {adversarial linear bandit EXP2 with John distribution (intractable) minimax optimal when A is finite Efficient Miror-Descent based algorithm for two situation (combinatorial case and euclidian ball) For A and Z as the euclidian ball, we get a upper bound on the regret of sqrt(dn) -> There is no current lower bound for given A and Z!},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@InProceedings{BubeckLiu:13,
  Title                    = {{Prior-free and prior-dependent regret bounds for Thompson Sampling}},
  Author                   = {Bubeck, S. and Liu, C.-Y.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@Article{Bubeckal11,
  Title                    = {{Pure Exploration in Finitely Armed and Continuous Armed Bandits}},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G.},
  Journal                  = {Theoretical Computer Science 412, 1832-1852},
  Year                     = {2011},
  Pages                    = {1832--1852},
  Volume                   = {412},

  Abstract                 = {algorithm minimizing the simple regret at round n correspond to a different set of application : you don't care making error in the exploration phase and just have to make a good recomandation for the arm in the end -> pure exploration, interesting applications (Marjorie?) forecaster : pair of an allocation (how to deal with exploration) and a recomandation (what you advice at a given stage if you have to stop exploring) -> (or try to) version of the pure exploration problem a strategy that has low cummulative regret (for its exploration phase) has a simple regret that is lower bounded ! lower bound for the simple regret (Bernoulli) : exponential decay, unlike what is achieved with an UCB exploration upper bound on the simple regret for strategy including UCB and the uniform exploration (which turns to be optimal coupled with an recommandation based on the empirical mean)},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@ARTICLE{GMS18,
	TITLE = {Explore First, Exploit Next: The True Shape of Regret in Bandit Problems},
	AUTHOR = {Aurélien Garivier and Pierre Ménard and Gilles Stoltz},
	JOURNAL = {Mathematics of Operations Research},
	YEAR = {2016},
	ARXIV = {1602.07182},
	HAL = {01276324},
}

@ARTICLE{Thall07,
	TITLE = {Practical Bayesian Adaptive Randomization in Clinical Trials},
	AUTHOR = {P.F. Thall and J.K. Wathen},
	JOURNAL = {European Journal on Cancer},
	YEAR = {2007},
	VOLUME = {43},
	PAGES = {859-866}
}

@ARTICLE{StanManual,
	TITLE = {Stan Modeling Language Users Guide and Reference Manual},
	AUTHOR = {{Stan Development Team}},
	JOURNAL = {http://mc-stan.org},
	YEAR = {2015},
	VOLUME = {version 2.8.0}
}



@Article{Bubeck11Xarmed,
  Title                    = {X-armed bandits},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G. and Szepesv\'{a}ri, C.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {1587-1627},
  Volume                   = {12},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{BPR13,
  Title                    = {{Bounded regret in stochastic multi-armed bandits}},
  Author                   = {Bubeck, S. and Perchet, V. and Rigollet, P.},
  Booktitle                = {{Proceedings of the 26th Conference On Leaning Theory}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{Bubeck:alMult13,
  Title                    = {{Multiple Identifications in multi-armed bandits}},
  Author                   = {Bubeck, S. and Wang, T. and Viswanathan, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Abstract                 = {An algorithm for finding the m best arms in a pure-exploration setting with known horizon n upper bound the probability of error at time t (no matching lower bound) Successive Acepts and Rejects algorithms : suprinsingly enough, the Successive Reject does not work !},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@Article{Bull11EI,
  Title                    = {{Convergence Rates of Efficient Global Optimization Algorithms}},
  Author                   = {Bull, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {2879--2904},
  Volume                   = {12},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@Article{BurnKat03OneArmed,
  Title                    = {{Asymptotic Bayes Analysis for the finite horizon one armed bandit problem}},
  Author                   = {Burnetas, A. and Katehakis, M.},
  Journal                  = {Probability in the Engineering and Informational Sciences},
  Year                     = {2003},
  Pages                    = {53--82},
  Volume                   = {17},

  Abstract                 = {contains an asymptotic resolution of the B\_lambda problem for two arms in the exponential family ! draws no parallel with Gittins index proposes an alternative exploration rate},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.21}
}

@Article{Burn:Kat:MDP97,
  Title                    = {{Optimal adaptive policies for {M}arkov decision processes}},
  Author                   = {Burnetas, A.N. and Katehakis, M.N.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {1997},
  Pages                    = {222--255},

  Publisher                = {Institute for Operations Research and the Management Sciences}
}

@Article{BurnKat96,
  Title                    = {{Optimal adaptive policies for sequential allocation problems}},
  Author                   = {Burnetas, A.N and Katehakis, M.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1996},
  Pages                    = {122--142},
  Volume                   = {17(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{KLUCBJournal,
  Title                    = {{{K}ullback-{L}eibler upper confidence bounds for optimal sequential allocation}},
  Author                   = {Capp{\'e}, O. and Garivier, A. and Maillard, O-A. and Munos, R. and Stoltz, G.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {1516--1541},
  Volume                   = {41(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.31}
}

@InProceedings{Marc12SideInfo,
  Title                    = {Levaraging Side Observations in Stochastic Bandits},
  Author                   = {Caron, S. and Kveton, B. and Lelarge, M. and Bhagat, S.},
  Booktitle                = {Conference on Uncertainty in Artificial Intelligence (UAI)},
  Year                     = {2012},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@InProceedings{carpentier2015simple,
  Title                    = {{Simple regret for infinitely many armed bandits}},
  Author                   = {Carpentier, Alexandra and Valko, Michal},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2015},

  Abstract                 = {We consider a stochastic bandit problem with infinitely many arms. In this setting, the learner has no chance of trying all the arms even once and has to dedicate its limited number of samples only to a certain number of arms. All previous algorithms for this setting were designed for minimizing the cumulative regret of the learner. In this paper, we propose an algorithm aiming at minimizing the simple regret. As in the cumulative regret setting of infinitely many armed bandits, the rate of the simple regret will depend on a parameter {\$}\backslashbeta{\$} characterizing the distribution of the near-optimal arms. We prove that depending on {\$}\backslashbeta{\$}, our algorithm is minimax optimal either up to a multiplicative constant or up to a {\$}\backslashlog(n){\$} factor. We also provide extensions to several important cases: when {\$}\backslashbeta{\$} is unknown, in a natural setting where the near-optimal arms have a small variance, and in the case of unknown time horizon.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{ESAIM17,
  Title                    = {{Learning the distribution with largest mean: two bandit frameworks}},
  Author                   = {Kaufmann, E. and Garivier, A.},
  Journal                  = {ESAIM: Proceedings and Surveys},
  Year                     = {2017},
  Pages                    = {114--131},
  Volume                   = {60}
}


@Article{Comband12,
  Title                    = {{Combinatorial Bandits}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Journal                  = {Journal of Computer and System Sciences},
  Year                     = {2012},
  Pages                    = {1404--1422},
  Volume                   = {78},

  Abstract                 = {adversarial linear bandit with D={0,1}^d COMBAND algorithm (not always enjoying a good regret, depends on an exploration distribution) a lot of funny example},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Book{PLG06,
  Title                    = {{Prediction, Learning and Games}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Publisher                = {Cambridge University Press},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@InProceedings{Chandra14COLT,
  Title                    = {{Finding a most biaised coin with fewest flips}},
  Author                   = {Chandrasekaran, K. and Karp, R.},
  Booktitle                = {{Proceeding of the 27th Conference on Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{ChangLai87,
  Title                    = {{Optimal stopping and dynamic allocation}},
  Author                   = {Chang, F. and Lai, T.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1987},
  Pages                    = {829--853},
  Volume                   = {19},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@InProceedings{LiChapelle11,
  Title                    = {{An empirical evaluation of Thompson Sampling}},
  Author                   = {Chapelle, O. and Li, L.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@Article{Chapelleetal14Ad,
  Title                    = {{Simple and scalable response prediction for display advertising.}},
  Author                   = {Chapelle, O. and Manavoglu, E. and Rosales, R.},
  Journal                  = {Transactions on Intelligent Systems and Technology},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{Chen14ComBAI,
  Title                    = {{Combinatorial Pure Exploration of Multi-Armed Bandits}},
  Author                   = {Chen, S. and Lin, T. and King, I. and Lyu, M. and Chen, W.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014}
}

@TechReport{Chernoff:Tech67,
  Title                    = {{Optimal stochastic control}},
  Author                   = {Chernoff, H.},
  Institution              = {Stanford, California},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.05}
}

@InProceedings{Chernoff67,
  Title                    = {{Sequential models for clinical trials}},
  Author                   = {Chernoff, H.},
  Booktitle                = {{Fifth Berkeley Symposium on Mathematical Statistics and Probability}},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@Article{Villar15BCT,
  Title                    = {{Multi-armed Bandit Models for the Optimal Design of Clinical Trials: Benefits and Challenges}},
  Author                   = {Villar, S. and Bowden, J. and Wason, J.},
  Journal                  = {Statistical Science},
  Year                     = {2015},
  Number                   = {2},
  Pages                    = {199--215},
  Volume                   = {30}
}

@Article{OQuigley90CRM,
  Title                    = {{Continual reassessment method: a practical design for phase 1 clinical trials in cancer}},
  Author                   = {O'Quigley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Pages                    = {33--48},
  Volume                   = {46}
}

@Article{Chernoff59,
  Title                    = {{Sequential design of Experiments}},
  Author                   = {Chernoff, H.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1959},
  Number                   = {3},
  Pages                    = {755--770},
  Volume                   = {30}
}


@Article{Chernoff:Ray65,
  Title                    = {{A Bayes sequential sampling inspection plan}},
  Author                   = {Chernoff, H. and Ray, S.N.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1965},
  Pages                    = {1387--1407},
  Volume                   = {36},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@InProceedings{LinUCB11,
  Title                    = {{Contextual Bandits with Linear Payoff Functions}},
  Author                   = {Chu, W. and Li, L. and Reyzin, L. and Schapire, R.},
  Booktitle                = {{Proceedings of the 14th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Article{ClopperPearson34,
  Title                    = {{The use of confidence of fiducial limits illustration in the case of the binomial}},
  Author                   = {Clopper, C.J. and Pearson, E.S.},
  Journal                  = {Biometrika},
  Year                     = {1934},
  Pages                    = {404--413},
  Volume                   = {26}
}

@Article{Combes15JSAC,
  Title                    = {{Dynamic Rate and Channel Selection in Cognitive Radio Systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Journal                  = {IEEE Journal on Selected Area in Communication},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{Combes14COLT,
  Title                    = {Unimodal bandits: Regret lower bounds and optimal algorithms},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@TechReport{Combes14Unimodal,
  Title                    = {{Unimodal Bandits without Smoothness}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Year                     = {2014},

  Booktitle                = {{arXiv:1406.7447}}
}

@Conference{Combes14802,
  Title                    = {{Optimal rate sampling in 802.11 systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A. and Yun, D. and Ok, J. and Yi, Y.},
  Booktitle                = {{IEEE INFOCOM}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{CombUCB15,
  Title                    = {Combinatorial bandits revisited},
  Author                   = {Combes, R. and Talebi, S. and Prouti{\`e}re, A. and Lelarge, M.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.30}
}

@InProceedings{Vayatis13GP,
  Title                    = {{Parallel Gaussian Process Optimization with Upper Confidence Bounds and Pure Exploration}},
  Author                   = {Contal, E. and Buffoni, D. and Vayatis, N.},
  Booktitle                = {{Proceedings of the European Conference on Machine Learning}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.17}
}

@Book{Cover:Thomas,
  Title                    = {{Elements of Information Theory (2nd Edition)}},
  Author                   = {Cover, T. and Thomas, J.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.29}
}


@Book{CRMBook,
  Title                    = {{Dose Finding by the Continuous Reassessment Method}},
  Author                   = {Cheung, Y-K.},
  Editor                   = {Chapman and Hall},
  Publisher                = {CRC Press},
  Year                     = {2011},
}

@InProceedings{Danial08,
  Title                    = {{Stochastic Linear Optimization under Bandit Feedback}},
  Author                   = {Dani, V. and Hayes, T.P. and Kakade, S.M.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2008},
  Pages                    = {355--366},

  Abstract                 = {stochastic linear bandit, dual setting algo Confidence Ball (L1 and L2) Minimax Lower bound d*sqrt(n) (rather adversarial) on the hypercube Upper bound in high probability on the regret - problem dependant when Delta>0 - problem independant},
  Journal                  = {Conference On Learning Theory (COLT)},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}

@InProceedings{Danial07,
  Title                    = {{The Price of Bandit Information in Online Optimization}},
  Author                   = {Dani, V. and Hayes, T. and Kakade, S.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2007},

  Abstract                 = {adversarial linear bandit (oblivious?) mention of a lower bound (not very clear, see their paper from 2008) (on the hypercube) Geometric Hedge algorithm},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Article{DeLaPenaal04,
  Title                    = {{Self-Normalized Processes: Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {{De La Pena}, V. and Klass, M. and Lai, T.L.},
  Journal                  = {The Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DeLaPenaal09Book,
  Title                    = {{Self-normalized processes. Limit Theory and Statistical applications}},
  Author                   = {{De La Pena}, V.H. and Lai, T.L. and Q., Shao},
  Publisher                = {Springer},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DemboZeitouni,
  Title                    = {{Large Deviations Techniques and Applications, 2nd Edition}},
  Author                   = {Dembo, Amir and Zeitouni, Ofer},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.23}
}

@Article{Romaric14,
  Title                    = {{Efficient Eigen-updating for Spectral Graph Clustering}},
  Author                   = {Dhanjal, C. and Gaudel, R. and Cl{\'e}mencon, S.},
  Journal                  = {arXiv:1301.1318},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Conference{SpherCov06,
  Title                    = {{Covering spheres and balls with smaller balls}},
  Author                   = {Dumer, I.},
  Booktitle                = {{ISIT}},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Durand14AAAI,
  Title                    = {{Thompson Sampling for Combinatorial Bandits and Its Application to Online Feature Selection}},
  Author                   = {Durand, A. and Gagn{\'e}, C.},
  Booktitle                = {{AAAI-14 Workshop on Sequential Decision-Making with Big Data}},
  Year                     = {2014}
}

@Book{Durrett10,
  Title                    = {{Probability: Theory and Examples}},
  Author                   = {Durrett, R.},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.17}
}

@Article{Eckles14TSBootstrap,
  Title                    = {Thompson Sampling with the online bootstrap},
  Author                   = {Eckles, D. and Kaptein, M.},
  Journal                  = {arXiv:1410.4009},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.10.13}
}

@Article{EvenDaral06,
  Title                    = {{Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems}},
  Author                   = {Even-Dar, E. and Mannor, S. and Mansour, Y.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1079--1105},
  Volume                   = {7},

  Abstract                 = {Pure exploration problem of finding the best arm in a PAC setting (with a level epsilon of tolerance) Several algorithms are proposed, with successive elimination sometimes},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@Article{Feldman62,
  Title                    = {{Contributions to the ''two-armed bandit''}},
  Author                   = {Feldman, D.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1962},
  Pages                    = {947--956},
  Volume                   = {33(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@PhdThesis{filippi10,
  Title                    = {{Optimistic strategies in Reinforcement Learning \emph{(in French)}}},
  Author                   = {Filippi, S.},
  School                   = {Telecom ParisTech},
  Year                     = {2010},

  Url                      = {http://tel.archives-ouvertes.fr/tel-00551401}
}

@InProceedings{allerton10,
  Title                    = {{Optimism in Reinforcement Learning and {K}ullback-{L}eibler Divergence}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Allerton Conference on Communication, Control, and Computing}},
  Year                     = {2010},

  Address                  = {Monticello, US},

  Eprint                   = {1004.5229}
}

@InProceedings{Filippi:GLM10,
  Title                    = {{Parametric Bandits : The Generalized Linear case}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A. and Szepesv{\'a}ri, C.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@InProceedings{Fonteneaual13,
  Title                    = {{An optimistic posterior sampling strategy for Bayesian reinforcement learning}},
  Author                   = {Fonteneau, R. and Korda, N. and Munos, R.},
  Booktitle                = {{Workshop on Bayesian Optimization, NIPS}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@TechReport{Frostig:Weiss99,
  Title                    = {{Four proofs of {G}ittins' multiarmed bandit theorem}},
  Author                   = {Frostig, E. and Weiss, G.},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{Gabillon:al12,
  Title                    = {{Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence}},
  Author                   = {Gabillon, V. and Ghavamzadeh, M. and Lazaric, A.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.06}
}

@InProceedings{Aurelien13,
  Title                    = {{Informational Confidence Bounds for Self-Normalized Averages and Applications}},
  Author                   = {Garivier, A.},
  Booktitle                = {{IEEE Information Theory Workshop}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.20}
}

@InProceedings{AOKLUCB,
  Title                    = {{The {KL-UCB} algorithm for bounded stochastic bandits and beyond}},
  Author                   = {Garivier, A. and Capp{\'e}, O.},
  Booktitle                = {{Proceedings of the 24th Conference on Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{GK16,
  Title                    = {Optimal Best Arm Identification with Fixed Confidence},
  Author                   = {Garivier, Aur{\'e}lien and Kaufmann, Emilie},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory (to appear)},
  Year                     = {2016}
}

@InProceedings{GKK16,
  Title                    = {Maximin Action Identification: A New Bandit Framework for Games},
  Author                   = {Garivier, A. and Kaufmann, E. and Koolen, W.M.},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory (to appear)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.05.25}
}

@InProceedings{GarivierMoulines11,
  Title                    = {{On Upper-Confidence Bound Policies for Switching Bandit Problems}},
  Author                   = {Garivier, A. and Moulines, E.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GinebraClayton99,
  Title                    = {{Small-sample performance of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Journal                  = {Journal of Statistical Planning and Inference},
  Year                     = {1999},
  Pages                    = {107--122},
  Volume                   = {79(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@TechReport{GinebraClayton94TechReportFreq,
  Title                    = {{Small-sample frequentist properties of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Institution              = {University of Wisconsin},
  Year                     = {1994},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.05.31}
}

@Article{Gittins79,
  Title                    = {{Bandit processes and dynamic allocation indices}},
  Author                   = {Gittins, J.C.},
  Journal                  = {Journal of the Royal Statistical Society, Series B},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {148--177},
  Volume                   = {41},

  Keywords                 = {bandit},
  Publisher                = {JSTOR}
}

@Book{GittinsBook11,
  Title                    = {{Multi-armed bandit allocation indices (2nd Edition)}},
  Author                   = {Gittins, J. and Glazebrook, K. and Weber, R.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Gittins:Jones79,
  Title                    = {{A dynamic allocation index for the discounted multiarmed bandit problem}},
  Author                   = {Gittins, J.C. and Jones, D.M.},
  Journal                  = {Biometrika},
  Year                     = {1979},
  Number                   = {3},
  Pages                    = {561--565},
  Volume                   = {66},

  Keywords                 = {bandit},
  Publisher                = {Biometrika Trust}
}

@InProceedings{Gittins:Jones74,
  Title                    = {{A dynamic allocation index for the sequential design of experiments}},
  Author                   = {Gittins, J. and Jones, D.M.},
  Booktitle                = {{Progress in Statistics (proceedings of the 1972 European Meeting of Statisticians)}},
  Year                     = {1974},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{GlynnJuneja04,
  Title                    = {A large deviations perspective on ordinal optimization},
  Author                   = {Glynn, P. and Juneja, S.},
  Booktitle                = {Proceedings of the 2004 Winter Simulation Conference (IEEE)},
  Year                     = {2004},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@InProceedings{Gopalan14TSComplex,
  Title                    = {{Thompson Sampling for Complex Online Problems}},
  Author                   = {Gopalan, A. and Mannor, S. and Mansour, Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{GranmoBLA,
  Title                    = {{Solving two-armed Bernoulli Bandit Problems using a Bayesian Learning Automaton}},
  Author                   = {Granmo, O.C.},
  Journal                  = {International Journal of Intelligent Computing and Cybernetics},
  Year                     = {2010},
  Pages                    = {207--234},
  Volume                   = {3(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GravesLai97,
  Title                    = {{Asymptotically Efficient adaptive choice of control laws in controlled markov chains}},
  Author                   = {Graves, T.L. and Lai, T.L.},
  Journal                  = {SIAM Journal on Control and Optimization},
  Year                     = {1997},
  Pages                    = {715--743},
  Volume                   = {35(3)},

  Abstract                 = {generalisation de la borne de Lai et Robbins: - � des bandits om on a des informations pr�cise sur les param�tre des bras (e.g. bounded regret) - aux restless bandits (trop simple?) - aux switching bandits},
  Owner                    = {kaufmann},
  Timestamp                = {2013.07.15}
}

@InProceedings{grill2015black-box,
  Title                    = {{Black-box optimization of noisy functions with unknown smoothness}},
  Author                   = {Grill, Jean-Bastien and Valko, Michal and Munos, R{\'{e}}mi},
  Booktitle                = {Neural Information Processing Systems},
  Year                     = {2015},

  Abstract                 = {We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO's performance, which shows that its error after n evaluations is at most a factor of sqrt(ln n) away from the error of the best known optimization algorithms using the knowledge of the smoothness.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Guha14TSweird,
  Title                    = {{Stochastic Regret Minimization via Thompson Sampling}},
  Author                   = {Guha, S. and Munagala, K.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{HeidrichMeisneral09,
  Title                    = {{{H}oeffding and {B}ernstein Races for Selecting Policies in Evolutionary Direct Policy Search}},
  Author                   = {Heidrich-Meisner, V. and Igel, C.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2012.10.01}
}

@Article{Hoeffding63,
  Title                    = {{Probability inequalities for sums of bounded random variables}},
  Author                   = {Hoeffding, W.},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1963},
  Pages                    = {13:30},
  Volume                   = {58},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.19}
}

@InProceedings{Hoffmanal14,
  Title                    = {{On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning}},
  Author                   = {Hoffman, M. and Shahriari, B. and de Freitas, N.},
  Booktitle                = {{Proceedings of the 17th International Conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@InProceedings{HondaTakemura10,
  Title                    = {{An Asymptotically Optimal Bandit Algorithm for Bounded Support Models}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 23rd Conference on Learning Theory}},
  Year                     = {2010},
  Editor                   = {Kalai, T. and Mohri, M.}
}

@InProceedings{HondaTakemura14TS,
  Title                    = {{Optimality of Thompson Sampling for Gaussian Bandits depends on priors}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 17th conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{Auer:UCRL10,
  Title                    = {{Near-Optimal regret bounds for reinforcement learning}},
  Author                   = {Jaksch, T. and Ortner, R. and Auer, P.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {1563--1600},
  Volume                   = {11},

  Owner                    = {kaufmann},
  Timestamp                = {2013.02.28}
}

@Article{Marjorie15,
  Title                    = {{Sequential design of computer experiments for the assessment of fetus exposure to electromagnetic fields}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Journal                  = {Technometrics},
  Year                     = {2015},
  Volume                   = {to appear},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Jala:al12,
  Title                    = {{Sequential design of computer experiments for parameter estimation}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Booktitle                = {{EUSIPCO}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{Jamieson15Duel,
  Title                    = {{Sparse Dueling Bandits}},
  Author                   = {Jamieson, K. and Katariya, S. and Deshpande, A. and Nowak, R.},
  Booktitle                = {{Proceedings of the 18th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2015.02.07}
}

@InProceedings{Jamiesonal14LILUCB,
  Title                    = {{lil'{UCB}: an Optimal Exploration Algorithm for Multi-Armed Bandits}},
  Author                   = {Jamieson, K. and Malloy, M. and Nowak, R. and Bubeck, S.},
  Booktitle                = {{Proceedings of the 27th Conference on Learning Theory}},
  Year                     = {2014},

  Journal                  = {arXiv:1312.7308},
  Owner                    = {kaufmann},
  Timestamp                = {2014.01.22}
}

@Article{Jeffreys46,
  Title                    = {{An invariant form for prior probability in estimation problems}},
  Author                   = {Jeffreys, H.},
  Journal                  = {Proceedings of the Royal Society of London, Serie A.},
  Year                     = {1946},
  Pages                    = {453--461},
  Volume                   = {286},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Article{Jennisonal84,
  Title                    = {{Asymptotically optimal procedures for sequential adaptive selection of the best of several normal means}},
  Author                   = {Jennison, Christopher and Johnstone, Iain M. and Turnbull, Bruce W.},
  Journal                  = {Statistical Decision Theory and Related Topics III},
  Year                     = {1982},
  Pages                    = {55--86},
  Volume                   = {2},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.24}
}

@Article{Jones:alEI98,
  Title                    = {{Efficient Global Optimization of Expensive Black-Box Functions}},
  Author                   = {Jones, Donal R. and Schonlau, Matthias and Welch, William},
  Journal                  = {Journal of Global Optimization},
  Year                     = {1998},
  Pages                    = {455--492},
  Volume                   = {13(4)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{JunNowak16,
  Title                    = {Anytime exploration for Multi-armed Bandits using Confidence Information},
  Author                   = {Jun, K-W and Nowak, R.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@PhdThesis{Shivaram:PHD,
  Title                    = {{Learning Methods for Sequential Decision Making with Imperfect Representations}},
  Author                   = {Kalyanakrishnan, S.},
  School                   = {Departement of Computer Science, The University of Texas at Austin},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.19}
}

@InProceedings{Shivaram:al10,
  Title                    = {{Efficient Selection in Multiple Bandit Arms: Theory and Practice}},
  Author                   = {Kalyanakrishnan, S. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.09.05}
}

@InProceedings{Shivaramal12,
  Title                    = {{{PAC} subset selection in stochastic multi-armed bandits}},
  Author                   = {Kalyanakrishnan, S. and Tewari, A. and Auer, P. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@InProceedings{Karnin13,
  Title                    = {{Almost optimal Exploration in multi-armed bandits}},
  Author                   = {Karnin, Z. and Koren, T. and Somekh, O.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.21}
}

@Article{KatRob:95Gauss,
  Title                    = {{Sequential choice from several populations}},
  Author                   = {Katehakis, M. and Robbins, H.},
  Journal                  = {Proceedings of the National Academy of Science},
  Year                     = {1995},
  Pages                    = {8584--8585},
  Volume                   = {92},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.25}
}

@Article{AOS16,
  Title                    = {On Bayesian Index Policies for Sequential Resource Allocation},
  Author                   = {Kaufmann, E.},
  Journal                  = {Preprint arXiv:1601.01190},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.02.01}
}

@PhdThesis{MaThese,
  Title                    = {{Analyse de strat{\'e}gies bay{\'e}siennes et fr{\'e}quentistes pour l'allocation s{\'e}quentielle de ressources}},
  Author                   = {Kaufmann, E.},
  Year                     = {2014},

  Organization             = {Telecom ParisTech}
}

@Article{JMLR15,
  Title                    = {{On the Complexity of Best Arm Identification in Multi-Armed Bandit Models}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {1-42},
  Volume                   = {17},

  Booktitle                = {{arXiv:1407.4443}},
  Owner                    = {kaufmann},
  Timestamp                = {2014.07.15}
}

@InProceedings{COLT14,
  Title                    = {{On the Complexity of A/B Testing}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@InProceedings{AISTATS12,
  Title                    = {{On {B}ayesian {U}pper-{C}onfidence {B}ounds for Bandit Problems}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 15th conference on Artificial Intelligence and Statistics}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@inproceedings{Agrawal17TSRL,
  author    = {Shipra Agrawal and
               Randy Jia},
  title     = {Optimistic posterior sampling for reinforcement learning: worst-case
               regret bounds},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017}
}

@InProceedings{COLT13,
  Title                    = {{Information complexity in bandit subset selection}},
  Author                   = {Kaufmann, E. and Kalyanakrishnan, S.},
  Booktitle                = {{Proceeding of the 26th Conference On Learning Theory.}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{ALT12,
  Title                    = {{Thompson Sampling : an Asymptotically Optimal Finite-Time Analysis}},
  Author                   = {Kaufmann, E. and Korda, N. and Munos, R.},
  Booktitle                = {{Proceedings of the 23rd conference on Algorithmic Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@Book{RPS,
  Title                    = {{Requiem pour {S}tanley}},
  Author                   = {Kaufmann, S.},
  Publisher                = {Editions Lulu},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.08.24}
}

@Conference{Kocak14SpectralTS,
  Title                    = {{Spectral Thompson Sampling}},
  Author                   = {Koc{\'a}k, T. and Valko, M. and Munos, R. and Agrawal, S.},
  Booktitle                = {{International Conference on Machine Learning}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{KocsisBBMCP06,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, L. and Szepesv\'{a}ri, C.},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Comment-doi              = {10.1007/11871842_29},
  Comment-url              = {http://dx.doi.org/10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12}
}

@InProceedings{KocsisBBMCP06,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, Levente and Szepesv\'{a}ri, Csaba},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Doi                      = {10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12},
  Url                      = {http://dx.doi.org/10.1007/11871842_29}
}

@InProceedings{NIPS13,
  Title                    = {{Thompson Sampling for 1-dimensional Exponential family bandits}},
  Author                   = {Korda, N. and Kaufmann, E. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@InProceedings{Krause:11Context,
  Title                    = {{Contextual Gaussian Process Bandit Optimization}},
  Author                   = {Krause, A. and Ong, C.S.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@Article{Lai:SeqTest88,
  Title                    = {{Nearly Optimal Sequential Tests for Composite Hypotheses}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1988},
  Pages                    = {856--886},
  Volume                   = {16(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.12}
}

@Article{Lai88,
  Title                    = {{Boundary Crossing problems for samples means}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {1988},
  Pages                    = {375--396},
  Volume                   = {16(1)},

  Abstract                 = {present a general concentration inequality in terms of KL-divergence that is useful in a asymoptotic analysis for 'KL-UCB' provided in Lai87 and also for sequential hypothese testing},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.19}
}

@Article{Lai87,
  Title                    = {{Adaptive treatment allocation and the multi-armed bandit problem}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1987},
  Pages                    = {1091--1114},
  Volume                   = {15(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{LaiRobbins85bandits,
  Title                    = {{Asymptotically efficient adaptive allocation rules}},
  Author                   = {Lai, T.L. and Robbins, H.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Date-modified            = {2010-02-02 03:14:31 -0700},
  Publisher                = {Elsevier}
}


@article{Locatelli16Thres,
  title={An optimal algorithm for the Thresholding Bandit Problem},
  author={Locatelli, Andrea and Gutzeit, Maurilio and Carpentier, Alexandra},
  journal={arXiv preprint arXiv:1605.08671},
  year={2016}
}

@Article{Tor15Gittins,
  Title                    = {Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits},
  Author                   = {Lattimore, T.},
  Journal                  = {arXiv:1511.06014},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.27}
}

@Article{LaurentMassart00,
  Title                    = {{Adaptive estimation of a quadratic functional by model selection}},
  Author                   = {Laurent, B. and Massart, P},
  Journal                  = {Annals of Statistics},
  Year                     = {2000},
  Pages                    = {1302--1338},
  Volume                   = {28(5)},

  Abstract                 = {gives an upper bound on the quantile of a chi square distribution},
  Owner                    = {kaufmann},
  Timestamp                = {2013.11.28}
}

@InProceedings{Lelarge13Spectrum,
  Title                    = {{Spectrum Bandit Optimization}},
  Author                   = {Lelarge, M. and Prouti{\`e}re, A. and Talebi, S.},
  Booktitle                = {{ITW}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{LevinLeu:08AR,
  Title                    = {{On a Conjecture of Bechhofer, Kiefer, and Sobel for the Levin-Robbins-Leu Binomial Subset Selection Procedures}},
  Author                   = {Levin, B. and Leu, C.},
  Journal                  = {Sequential Analysis},
  Year                     = {2008},
  Pages                    = {106--125},
  Volume                   = {27},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@InProceedings{LiChapelle:OpenPb,
  Title                    = {{Open Problem: Regret Bounds for Thompson Sampling}},
  Author                   = {Li, L. and Chapelle, O.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@Article{LiuLi15,
  Title                    = {On the prior sensitivity of Thompson Sampling},
  Author                   = {Liu, C.-Y. and Li, L.},
  Journal                  = {arXiv:1506.03378},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@InProceedings{Combes14Lip,
  Title                    = {{Lipschitz Bandits: Regret lower bounds and optimal algorithms}},
  Author                   = {Magureanu, S. and Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {{Proceedings on the 27th Conference On Learning Theory}},
  Year                     = {2014}
}

@InProceedings{Maillard:al11KLUCB,
  Title                    = {{A Finite-Time Analysis of Multi-armed Bandits Problems with {K}ullback-{L}eibler Divergences}},
  Author                   = {Maillard, O-A. and Munos, R. and Stoltz, G.},
  Booktitle                = {{Proceedings of the 24th Conference On Learning Theory}},
  Year                     = {2011}
}

@Article{Mairal10OnlineNMF,
  Title                    = {{Online Learning for Matrix Factorization and Sparse Coding}},
  Author                   = {Mairal, J. and Bach, F. and Ponce, J. and Sapiro, G.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {19--60},
  Volume                   = {11},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{MannorTsi04,
  Title                    = {{The Sample Complexity of Exploration in the Multi-Armed Bandit Problem}},
  Author                   = {Mannor, S. and Tsitsiklis, J.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2004},
  Pages                    = {623--648},

  Abstract                 = {Setting: Fixed Confidence with epsilon>0, find the best arm (non asymptotic) lower bounds for Bernoulli rewrads: - a worst case LB scaling in epsilon - a LB scaling in epsilon and gaps but for parameter smaller than 1/2 (that involves some abstract parameter p -> not a sum over all arms) Thm 5 - a more complicated LB for 'general' parameter Thm 8 - a 'worse-case' Bayesian bound (there exists a prior) - a worst-case Lai and Robbins version (based on a Bayesian LB) in the regret setting - some stuff when the distributions are known},
  Owner                    = {kaufmann},
  Timestamp                = {2013.03.25}
}

@ARTICLE{Robbins52,
  author = {Robbins, H.},
  title = {{Some aspects of the sequential design of experiments}},
  journal = {Bulletin of the American Mathematical Society},
  year = {1952},
  volume = {58(5)},
  pages = {527--535},
  abstract = {First statement of the frequentist MAB Hannan consistent policies
	Looks for minmax rules epsilon greedy mentionned},
  owner = {kaufmann},
  timestamp = {2012.07.06}
}

@Article{MaronMoore:97,
  Title                    = {{The Racing algorithm: Model selection for Lazy learners}},
  Author                   = {Maron, O. and Moore, A.},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {1997},
  Pages                    = {113--131},
  Volume                   = {11(1-5)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.30}
}

@Book{massart2007,
  Title                    = {{Concentration inequalities and model selection}},
  Author                   = {Massart, P.},
  Publisher                = {Springer},
  Year                     = {2007},

  Address                  = {Berlin},
  Note                     = {Lectures from the 33rd Summer School on Probability Theory held in Saint-Flour, July 6--23, 2003},
  Series                   = {{Lecture Notes in Mathematics}},
  Volume                   = {1896},

  Pages                    = {xiv+337}
}

@Article{May:al12OBS,
  Title                    = {{Optimistic {B}ayesian sampling in contextual bandit problems}},
  Author                   = {May, B. and Korda, N. and A., Lee and D., Leslie},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2012},
  Pages                    = {2069--2106},
  Volume                   = {13},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@InProceedings{MellorShapiro13TSwitch,
  Title                    = {{Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection}},
  Author                   = {Mellor, J. and Shapiro, J.},
  Booktitle                = {{Proceeding of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{Mnih:Bernstein08,
  Title                    = {{Empirical {B}ernstein stopping}},
  Author                   = {Mnih, V. and Szepesv{\'a}ri, C. and Audibert, J-Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.08}
}

@InProceedings{MockusEI77,
  Title                    = {{On Bayesian methods for seeking the extremum and their application}},
  Author                   = {Mockus, Jonas},
  Booktitle                = {{Inf. Process. 77, Proc. IFIP Congr., Toronto 1977}},
  Year                     = {1977},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@Book{SurveyRemiMCTS,
  Title                    = {From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization and planning.},
  Author                   = {Munos, R.},
  Publisher                = {Foundations and Trends in Machine Learning},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {7},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@Article{Javidi13,
  Title                    = {{Active sequential hypothesis testing}},
  Author                   = {Naghshvar, M. and Javidi, T.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {2703--2738},
  Volume                   = {41(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Book{Neveu72,
  Title                    = {{Martingales {\`a} temps discret}},
  Author                   = {Neveu, Jacques},
  Publisher                = {Masson},
  Year                     = {1972},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.19}
}

@Article{NinoMora11Finite,
  Title                    = {{Computing a Classic Index for Finite-Horizon Bandits}},
  Author                   = {Nino-Mora, J.},
  Journal                  = {INFORMS Journal of Computing},
  Year                     = {2011},
  Pages                    = {254--267},
  Volume                   = {23(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@Article{Nino-Mora07,
  Title                    = {A (2/3)n3 Fast-Pivoting Algorithm for the Gittins Index and Optimal Stopping of a Markov Chain.},
  Author                   = {Niño-Mora, José},
  Journal                  = {INFORMS Journal on Computing},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {596-606},
  Volume                   = {19}
}

@Article{OQuingley90CRM,
  Title                    = {Continual Reassessment Method: A Practical Design for Phase {I} Clinical Trials in Cancer},
  Author                   = {O'Quingley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {33-48},
  Volume                   = {46},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@InProceedings{RussoVanRoy13RL,
  Title                    = {{(More) Efficient Reinforcement Learning Via Posterior Sampling}},
  Author                   = {Osband, I. and {Van Roy}, B. and Russo, D.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@Article{Paulson:94,
  Title                    = {{Sequential procedures for selecting the best one of k {K}oopman-{D}armois populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Sequential Analysis: Design Methods and Applications},
  Year                     = {1994},
  Pages                    = {207--220},
  Volume                   = {13},

  Abstract                 = {to pay, not found},
  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@Article{Paulson:64,
  Title                    = {{A sequential procedure for selecting the population with the largest mean from k normal populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1964},
  Pages                    = {174--180},
  Volume                   = {35},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@InProceedings{Pavlidis:al08IE,
  Title                    = {{Simulation studies of multi-armed bandits with covariates}},
  Author                   = {Pavlidis, N.G and Tasoulis, D.K. and Hand, D.J.},
  Booktitle                = {{10th Proceedings of the International Conference on Computer Modeling}},
  Year                     = {2008},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.04.16}
}

@Article{PenaSelf04,
  Title                    = {{Self-normalized Processes : Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {de la Pena, V.H. and Klass, M.J. and Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Conference{Preux14Opt,
  Title                    = {{Bandits attack function optimization}},
  Author                   = {Preux, P. and Munos, R. and Valko, M.},
  Booktitle                = {{IEEE Congress on Evolutionary Computation}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Book{Puterman94MDP,
  Title                    = {{Markov Decision Processes. Discrete Stochastic. Dynamic Programming.}},
  Author                   = {Puterman, M.L.},
  Publisher                = {Wiley},
  Year                     = {1994},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@PhdThesis{TheseMKR14,
  Title                    = {Designs adaptatifs de recherche de dose en encologie dans le cadre de combinaisons de molécules et de molécules ciblées},
  Author                   = {Riviere, M-K.},
  School                   = {Université Paris-Diderot},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@Article{Robbins70LIL,
  Title                    = {{Statistical Methods Related to the law of the iterated logarithm}},
  Author                   = {Robbins, H.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1970},
  Pages                    = {1397--1409},
  Volume                   = {41(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.01.21}
}

@Article{Robbins52Freq,
  Title                    = {{Some aspects of the sequential design of experiments}},
  Author                   = {Robbins, H.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1952},
  Pages                    = {527--535},
  Volume                   = {58(5)},

  Abstract                 = {First statement of the frequentist MAB Hannan consistent policies Looks for minmax rules epsilon greedy mentionned},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{RusTsi10,
  Title                    = {{Linearly Parameterized Bandits}},
  Author                   = {Rusmevichientong, P. and Tsitsiklis, J.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {2010},
  Pages                    = {395--411},
  Volume                   = {35(2)},

  Abstract                 = {stochastic linear bandit (regret and bayesian risk) -> no dual case (a priori) Lower bound on the regret for actions on the unit sphere (for regret and bayes risk) in the stochastic setting of O(d\sqrt(n)) PEGE algorithm (separate exploration and exploitation) matches the lower bound but is efficient only on (at least) compact and strongly convex sets of actions UE algorithm (action set included in some L2 bowl, subgaussian assumption on the noise) - regret bound (O(d\sqrt(n)\log^3(n))) in expactation but based on hp results - regret bound in the finite case where Delta is defined scaling in the gaps},
  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Russo16,
  Title                    = {Simple Bayesian algorithms for Best Arm Identification},
  Author                   = {Russo, D.},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@Article{RussoVanRoy13,
  Title                    = {{Learning to optimize via posterior sampling}},
  Author                   = {Russo, D. and {Van Roy}, B.},
  Journal                  = {Mathematics of Operations Research (to appear)},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@InProceedings{RussoVanRoy14IDS,
  Title                    = {Learning to optimize via information direct sampling},
  Author                   = {Russo, D. and Van Roy, B.},
  Booktitle                = {Advances in Neural Information Processing Systems (NIPS)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@InProceedings{SalomonAudibert:11Dev,
  Title                    = {{Deviations of stochastic bandit regret}},
  Author                   = {Salomon, A. and Audibert, J-Y.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Abstract                 = {PB : do Rn>Clog(n) have small probability answer : not so small for UCB, better when the horizon is known (negative result for anytime policy) UCB-H is better then UCB in terms of hp result (possible) PAC-UCB : fix our exploration rate building a sequence corresponding to our level of confidence},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@InProceedings{Sani:al12,
  Title                    = {{Risk-aversion in multi-armed bandits}},
  Author                   = {Sani, A. and Lazaric, A. and Munos, R.},
  Booktitle                = {{NIPS}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.07.18}
}

@Article{AmandineSTMALA,
  Title                    = {{A shrinkage-thresholding Metropolis adjusted Langevin algorithm for Bayesian variable selection}},
  Author                   = {Schreck, A. and Fort, G. and {Le Corff}, S. and Moulines, E.},
  Journal                  = {arXiv:1312.5658},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.06.23}
}

@Article{Scott10,
  Title                    = {{A modern Bayesian look at the multi-armed bandit}},
  Author                   = {Scott, S.L.},
  Journal                  = {Applied Stochastic Models in Business and Industry},
  Year                     = {2010},
  Pages                    = {639--658},
  Volume                   = {26},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@InProceedings{Shamir13Complexity,
  Title                    = {{On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization}},
  Author                   = {Shamir, O.},
  Booktitle                = {{Conference On Learning Theory}},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@Book{Siegmund:SeqAn,
  Title                    = {{Sequential Analysis}},
  Author                   = {Siegmund, D.},
  Publisher                = {Springer-Verlag},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.30}
}

@Book{PDMIA08,
  Title                    = {{Processus Decisionnels de Markov et Intelligence artificielle}},
  Author                   = {Sigaud, O. and Buffet, O.},
  Publisher                = {Herm{\`e}s},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.31}
}

@Article{deep.go,
  Title                    = {Mastering the game of Go with deep neural networks and tree search },
  Author                   = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  Journal                  = {Nature},
  Year                     = {2016},
  Pages                    = {484--489},
  Volume                   = {529}
}

@InProceedings{Snoek14BOpt,
  Title                    = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
  Author                   = {Snoek, J. and Lrochelle, H. and Adams, R.P.},
  Booktitle                = {{Advances on Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Soare14BAILin,
  Title                    = {{Best Arm Identification in Linear Bandit}},
  Author                   = {Soare, M. and Lazaric, A. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{GPUCB:Journal,
  Title                    = {{Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Journal                  = {IEEE Transactions on Information Theory},
  Year                     = {2012},
  Pages                    = {3250--3265},
  Volume                   = {58(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@InProceedings{SrinivasGPUCB,
  Title                    = {{Gaussian Process Optimization in the Bandit Setting : No Regret and Experimental Design}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Booktitle                = {{Proceedings of the International Conference on Machine Learning}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Strens00TSRL,
  Title                    = {{A Bayesian Framework for Reinforcement Learning}},
  Author                   = {Strens, Malcom},
  Booktitle                = {{ICML}},
  Year                     = {2000},

  Abstract                 = {Thompson in RL},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.10}
}

@InProceedings{STOP14,
  Title                    = {Optimistic Planning in Markov Decision Processes using a generative model},
  Author                   = {Szorenyi, B. and Kedenburg, G. and Munos, R.},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{Thompson35,
  Title                    = {{On the theory of apportionment}},
  Author                   = {Thompson, W.},
  Journal                  = {American Journal of Mathematics},
  Year                     = {1935},
  Pages                    = {450--456},
  Volume                   = {57},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@Article{Rajesh15Oddball,
  Title                    = {Learning to detect an oddball target},
  Author                   = {N.K. Vaidhyan and R. Sundaresan},
  Journal                  = {arXiv:1508.05572},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.17}
}

@InProceedings{valko2013stochastic,
  Title                    = {{Stochastic simultaneous optimistic optimization}},
  Author                   = {Valko, Michal and Carpentier, Alexandra and Munos, R{\'{e}}mi},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2013},

  Abstract                 = {We study the problem of global maximization of a function f given a finite number of evaluations perturbed by noise. We consider a very weak assumption on the function, namely that it is locally smooth (in some precise sense) with respect to some semi-metric, around one of its global maxima. Compared to previous works on bandits in general spaces (Kleinberg et al., 2008; Bubeck et al., 2011a) our algorithm does not require the knowledge of this semi-metric. Our algorithm, StoSOO, follows an optimistic strategy to iteratively construct upper confidence bounds over the hierarchical partitions of the function domain to decide which point to sample next. A finite-time analysis of StoSOO shows that it performs almost as well as the best specifically-tuned algorithms even though the local smoothness of the function is not known.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Valko:al13KernelUCB,
  Title                    = {{Finite-time analysis of kernelized contextual bandits}},
  Author                   = {Valko, M. and Korda, N. and Munos, R. and Cristinini, N.},
  Booktitle                = {{29th Conference on Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Book{VdV:Asymptotic98,
  Title                    = {{Asymptotic Statistics}},
  Author                   = {{Van der Vaart}, A.},
  Publisher                = {Cambridge University Press},
  Year                     = {1998},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

