\subsection{Conclusion}
In this chapter, we introduced an efficient exact greedy-optimal algorithm, \texttt{Adaptive-Pruning Boost}, for boosted decision trees. Our experiments on various datasets show that our algorithm use fewer total example assessments compared to the-state-of-the-art algorithm \texttt{Quick Boost}. We further showed that \texttt{Adaptive-Pruning Boost} almost matches the lower bound for its class of algorithms and the global lower bound for any algorithm.
